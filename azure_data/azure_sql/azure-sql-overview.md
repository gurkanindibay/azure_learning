# Azure SQL - Complete Overview

## Table of Contents

- [Introduction](#introduction)
- [Azure SQL Product Family](#azure-sql-product-family)
- [Azure SQL Database](#azure-sql-database)
  - [Deployment Options](#deployment-options)
  - [Purchasing Models](#purchasing-models)
  - [Service Tiers](#service-tiers)
  - [Compute Tiers](#compute-tiers)
  - [High Availability and Zone Redundancy](#high-availability-and-zone-redundancy)
- [Azure SQL Managed Instance](#azure-sql-managed-instance)
- [SQL Server on Azure VMs](#sql-server-on-azure-vms)
- [Pricing Tiers Comparison](#pricing-tiers-comparison)
- [Feature Comparison](#feature-comparison)
- [Decision Guide](#decision-guide)
- [Migration to Azure SQL](#migration-to-azure-sql)
- [Best Practices](#best-practices)
- [Common Scenarios and Recommendations](#common-scenarios-and-recommendations)
- [Key Insights for Exams](#key-insights-for-exams)
- [References](#references)

> üìñ **For comprehensive migration information**, see the dedicated **[Azure SQL Migration Guide](./azure-sql-migration-guide.md)**

## Introduction

**Azure SQL** is a family of managed SQL Server database services running in the Azure cloud. It provides a range of deployment options from fully managed PaaS databases to infrastructure-as-a-service (IaaS) virtual machines, catering to different migration scenarios, workload requirements, and management preferences.

### Key Benefits

- **Fully Managed**: Automated patching, backups, and high availability
- **Built-in Intelligence**: Performance recommendations and automatic tuning
- **Scalability**: Scale up/down or scale out based on demand
- **Security**: Built-in advanced security features
- **Cost Optimization**: Pay only for what you use with flexible pricing models
- **High Availability**: Built-in 99.99%+ SLA

## Azure SQL Product Family

Azure SQL consists of three main products:

| Product | Type | Best For | Management Level |
|---------|------|----------|------------------|
| **Azure SQL Database** | PaaS | Modern cloud applications | Fully managed |
| **Azure SQL Managed Instance** | PaaS | Lift-and-shift migrations | Nearly 100% SQL Server compatibility |
| **SQL Server on Azure VMs** | IaaS | Full SQL Server control | Self-managed |

### Product Selection Flow

```
Need full SQL Server control? 
‚îî‚îÄ YES ‚Üí SQL Server on Azure VMs
‚îî‚îÄ NO ‚Üí Need instance-scoped features?
    ‚îî‚îÄ YES ‚Üí SQL Managed Instance
    ‚îî‚îÄ NO ‚Üí SQL Database
```

## Azure SQL Database

**Azure SQL Database** is a fully managed platform as a service (PaaS) database engine that handles database management functions including upgrading, patching, backups, and monitoring without user involvement.

### Deployment Options

#### 1. Single Database
**Isolated database with dedicated resources**

- Fully isolated resources
- Independent scaling and management
- Best for modern cloud applications
- Supports serverless compute tier
- Per-second billing available

**Use Cases**:
- Modern SaaS applications
- Microservices architectures
- Development/test environments
- Applications with predictable or unpredictable workloads (serverless)

#### 2. Elastic Pool
**Collection of databases sharing a set of resources**

- Shared resource pool across multiple databases
- Cost-effective for multiple databases
- Pool-level resource management
- Databases can have varying usage patterns

**Use Cases**:
- Multi-tenant SaaS applications
- Multiple databases with complementary usage patterns
- Cost optimization across database portfolio
- Unpredictable usage per database, but predictable aggregate

### Purchasing Models

Azure SQL Database offers two purchasing models:

#### vCore-Based Model (Recommended)

**Virtual Core (vCore)** model provides granular control over compute and storage resources.

**Characteristics**:
- Choose number of vCores (virtual cores)
- Choose memory (tied to vCore count)
- Choose storage independently
- Choose generation (Gen5, newer hardware)
- Better cost optimization
- Hybrid Benefit eligibility

**Components**:
```
Compute (vCores) + Storage (GB) + Backup Storage = Total Cost
```

**vCore Options**:
- 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 24, 32, 40, 64, 80, 128 vCores
- Memory: ~5.1 GB per vCore (Gen5)

#### DTU-Based Model

**Database Transaction Unit (DTU)** is a blended measure of compute, memory, and I/O.

**Characteristics**:
- Simplified pricing - bundled resources
- Fixed ratios of CPU, memory, I/O
- Less flexibility
- Easier to understand for beginners
- No Hybrid Benefit

**DTU Tiers**:
- Basic: 5 DTUs
- Standard: 10, 20, 50, 100, 200, 400, 800, 1600, 3000 DTUs
- Premium: 125, 250, 500, 1000, 1750, 4000 DTUs

### Service Tiers

Azure SQL Database offers three service tiers with different performance and pricing characteristics:

#### General Purpose (Recommended for most workloads)

**Budget-oriented balanced compute and storage**

**Characteristics**:
- Standard availability: 99.99% SLA
- Remote storage (Azure Premium Storage)
- Storage: 1 GB - 4 TB (depends on vCore)
- Latency: 5-10ms
- Backup retention: 7-35 days

**Pricing (vCore)**:
- 2 vCores: ~$360/month
- 4 vCores: ~$720/month
- 8 vCores: ~$1,440/month

**Use Cases**:
- Most business workloads
- Development and test
- Web applications
- Small to medium-sized databases

#### Business Critical (High performance requirements)

**Highest performance and availability**

**Characteristics**:
- Premium availability: 99.99% SLA (99.995% zone-redundant)
- Local SSD storage
- Storage: 1 GB - 4 TB
- Latency: <2ms
- Built-in read replicas (1 free)
- Zone redundancy available

**Pricing (vCore)**:
- 2 vCores: ~$900/month
- 4 vCores: ~$1,800/month
- 8 vCores: ~$3,600/month

**Use Cases**:
- Mission-critical applications
- Low-latency requirements
- High transaction rate
- Read scale-out scenarios

#### Hyperscale (Massive databases)

**Highly scalable storage and compute**

**Characteristics**:
- Storage: Up to 100 TB
- Fast scaling (minutes, not hours)
- Multiple read replicas (up to 4)
- Fast backup and restore
- Independent compute and storage scaling

**Pricing (vCore)**:
- 2 vCores: ~$500/month
- 4 vCores: ~$1,000/month
- Plus storage costs (~$0.12/GB/month)

**Use Cases**:
- Very large databases (> 4 TB)
- Applications requiring rapid scale-up/down
- Need for multiple read replicas
- Fast backup/restore requirements

### Compute Tiers

#### Provisioned Compute

**Fixed resources allocated continuously**

**Characteristics**:
- Fixed compute size (always on)
- Predictable performance
- Billed per hour
- Best for steady workloads

**Pricing Example (General Purpose, 4 vCores)**:
```
Compute: 4 vCores √ó 24 hours √ó 30 days = $720/month
Storage: 100 GB √ó $0.12/GB = $12/month
Total: ~$732/month
```

**Use Cases**:
- Production applications
- Consistent usage patterns
- 24/7 availability requirements

#### Serverless Compute ‚≠ê

**Auto-scaling compute with auto-pause**

**Characteristics**:
- Auto-scales between min and max vCores
- Auto-pauses during inactivity
- Per-second billing
- Automatic resume on connection

**Configuration**:
```
Min vCores: 0.5 - 40
Max vCores: 0.5 - 40
Auto-pause delay: 1 hour - 7 days (or disabled)
```

**Pricing Example (General Purpose, 0.5-4 vCores)**:
```
Active time: 8 hours/day at avg 2 vCores
Paused time: 16 hours/day

Compute: (8 √ó 2 vCores √ó 30 days) = ~$144/month
Storage: 100 GB √ó $0.12/GB = $12/month
Total: ~$156/month (vs $732 provisioned)
```

**Cost Savings**: Up to 80% for intermittent workloads

**Use Cases**:
- Development and test environments
- Unpredictable or intermittent workloads
- Infrequently used applications
- New applications with unknown patterns
- Cost optimization

**Limitations**:
- Only available in General Purpose tier
- Not available in Hyperscale (preview support varies)
- Resume delay (few seconds) on first connection after pause

### Service Tier Comparison Table

| Feature | General Purpose | Business Critical | Hyperscale |
|---------|----------------|-------------------|------------|
| **Use Case** | Most workloads | Mission-critical | Very large databases |
| **Storage Type** | Remote (Premium) | Local SSD | Multi-tier storage |
| **Max Storage** | 4 TB | 4 TB | 100 TB |
| **IOPS** | Up to 7,000 | Up to 200,000+ | Depends on replicas |
| **Latency** | 5-10ms | 1-2ms | 5-10ms (primary) |
| **Read Replicas** | ‚ùå | ‚úÖ 1 included | ‚úÖ Up to 4 |
| **Zone Redundancy** | ‚úÖ Optional | ‚úÖ Optional | ‚úÖ Available |
| **Backup Retention** | 7-35 days | 7-35 days | 7-35 days |
| **Restore Time** | Depends on size | Depends on size | Fast (minutes) |
| **Serverless** | ‚úÖ | ‚ùå | ‚ö†Ô∏è Preview | 
| **Price (4 vCore)** | ~$720/mo | ~$1,800/mo | ~$1,000/mo + storage |

### High Availability and Zone Redundancy

Azure SQL Database provides built-in high availability features that vary by service tier. Understanding these capabilities is crucial for designing business continuity solutions.

#### High Availability Architecture by Tier

**vCore-Based Service Tiers (General Purpose, Business Critical, Hyperscale)**:

##### General Purpose (vCore)
- **Standard Availability**: 99.99% SLA
- **Architecture**: Remote storage with compute node redundancy
- **Failover**: Automatic failover to standby replica
- **Zone Redundancy**: ‚úÖ Available (optional configuration)
- **RPO (Recovery Point Objective)**: Typically < 30 seconds
- **RTO (Recovery Time Objective)**: Typically < 30 seconds
- **Data Loss During Failover**: Minimal (transactions in flight may be lost)

##### Business Critical (vCore)
- **Premium Availability**: 99.99% SLA (99.995% with zone redundancy)
- **Architecture**: Always On availability groups with local SSD storage
- **Failover**: Automatic failover with zero data loss
- **Zone Redundancy**: ‚úÖ Available (optional configuration)
- **RPO (Recovery Point Objective)**: **0 (zero data loss)**
- **RTO (Recovery Time Objective)**: Typically < 30 seconds
- **Built-in Read Replicas**: 1 included for read scale-out
- **Data Loss During Failover**: **None** - fully synchronous replication

##### Hyperscale (vCore)
- **Availability**: 99.99% SLA (99.995% with zone redundancy)
- **Architecture**: Multi-tier storage with compute nodes
- **Failover**: Fast failover to standby compute nodes
- **Zone Redundancy**: ‚úÖ Available (optional configuration)
- **RPO**: Typically < 30 seconds
- **RTO**: Typically < 30 seconds
- **Read Replicas**: Up to 4 named replicas
- **Note**: Does not support automatic failover with zero data loss like Business Critical

**DTU-Based Service Tiers (Basic, Standard, Premium)**:

##### Basic (DTU)
- **Availability**: 99.99% SLA
- **Architecture**: Single database instance with basic redundancy
- **Failover**: Automatic but slower recovery
- **Zone Redundancy**: ‚ùå Not supported
- **RPO**: Up to 60 seconds
- **RTO**: Can be several minutes
- **Use Case**: Non-critical, small workloads only
- **Limitations**: No zone redundancy, no active geo-replication

##### Standard (DTU)
- **Availability**: 99.99% SLA
- **Architecture**: Standard redundancy with remote storage
- **Failover**: Automatic failover to standby
- **Zone Redundancy**: ‚ùå Not supported
- **RPO**: Typically < 30 seconds
- **RTO**: Typically < 30 seconds
- **Data Loss During Failover**: Possible (transactions in flight)
- **Limitations**: No zone redundancy support

##### Premium (DTU)
- **Premium Availability**: 99.99% SLA (99.995% with zone redundancy)
- **Architecture**: Always On availability groups (similar to Business Critical)
- **Failover**: Automatic failover with zero data loss
- **Zone Redundancy**: ‚úÖ **Supported**
- **RPO (Recovery Point Objective)**: **0 (zero data loss)**
- **RTO (Recovery Time Objective)**: Typically < 30 seconds
- **Active Geo-Replication**: ‚úÖ Supported
- **Built-in Read Replicas**: 1 included for read scale-out
- **Data Loss During Failover**: **None** - fully synchronous replication

#### Zone Redundancy Support Summary

| Tier | Zone Redundancy | Zero Data Loss Failover | Cost Efficiency |
|------|----------------|-------------------------|-----------------|
| **Basic (DTU)** | ‚ùå No | ‚ùå No | Lowest cost, minimal HA |
| **Standard (DTU)** | ‚ùå No | ‚ùå No | Low cost, basic HA |
| **Premium (DTU)** | ‚úÖ **Yes** | ‚úÖ **Yes** | ‚úÖ **Best for HA + cost** |
| **General Purpose (vCore)** | ‚úÖ Yes | ‚ùå No | Medium cost |
| **Business Critical (vCore)** | ‚úÖ Yes | ‚úÖ Yes | Highest cost |
| **Hyperscale (vCore)** | ‚úÖ Yes | ‚ùå No | High cost + scale |

#### Choosing the Right Tier for High Availability

**Scenario: Zero Data Loss + Zone Redundancy + Cost Optimization**

**Requirements**:
1. ‚úÖ Failover between replicas must occur without any data loss (RPO = 0)
2. ‚úÖ Database must remain available during a zone outage
3. ‚úÖ Minimize costs

**Solution**: **Azure SQL Database Premium (DTU)** ‚≠ê

**Why Premium is the Correct Choice**:

1. **Zero Data Loss (RPO = 0)**:
   - Uses Always On availability groups
   - Synchronous replication to secondary replicas
   - Automatic failover with no data loss

2. **Zone Redundancy**:
   - Supports zone-redundant configuration
   - Distributes replicas across availability zones
   - Database remains available during zone failures

3. **Cost Optimization**:
   - Less expensive than Business Critical (vCore)
   - Comparable high availability features
   - Suitable for most mission-critical workloads

**Why Other Tiers Don't Meet Requirements**:

‚ùå **Basic (DTU)**:
- No zone redundancy support
- Cannot guarantee zero data loss
- Not suitable for mission-critical workloads

‚ùå **Standard (DTU)**:
- No zone redundancy support
- Possible data loss during failover
- Not designed for high availability scenarios

‚ùå **Business Critical (vCore)**:
- ‚úÖ Meets all technical requirements
- ‚ùå More expensive than Premium DTU
- ‚ùå Does not minimize costs (violates requirement #3)

‚ùå **Hyperscale (vCore)**:
- ‚úÖ Supports zone redundancy
- ‚ùå Does not guarantee zero data loss (RPO not 0)
- ‚ùå Optimized for scale, not zero-data-loss HA
- ‚ùå Higher cost for features not needed

‚ùå **General Purpose (vCore)**:
- ‚úÖ Supports zone redundancy
- ‚ùå Does not guarantee zero data loss
- ‚ùå Uses remote storage, not Always On

#### Key Insights for Business Continuity Solutions

**For Zero Data Loss Requirements**:
- Choose **Premium (DTU)** or **Business Critical (vCore)**
- Both use Always On availability groups
- Both provide synchronous replication
- Both support zone redundancy

**For Zone Outage Protection**:
- Enable zone-redundant configuration
- Available in: Premium, General Purpose (vCore), Business Critical (vCore), Hyperscale
- NOT available in: Basic, Standard

**For Cost Optimization with High Availability**:
- **Premium (DTU)** offers the best balance
- Provides enterprise-grade HA at lower cost than Business Critical
- Suitable for most mission-critical workloads

**For Active Geo-Replication**:
- Supported in Premium and Business Critical
- Enables read-scale and disaster recovery across regions
- Automatic failover groups provide seamless failover

#### References
- [Azure SQL Database High Availability](https://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla-local-zone-redundancy?view=azuresql&tabs=azure-powershell)
- [Azure SQL Database Service Tiers (DTU)](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-dtu?view=azuresql)
- [Azure SQL Database Hyperscale](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale?view=azuresql)

## Azure SQL Managed Instance

**Azure SQL Managed Instance** is a fully managed instance of SQL Server providing near 100% compatibility with SQL Server Enterprise Edition, making it ideal for lift-and-shift migrations.

### Key Features

#### Instance-Scoped Features
- SQL Server Agent
- Service Broker
- Database Mail
- Distributed transactions
- CLR (Common Language Runtime)
- Linked servers
- Cross-database queries

#### Networking
- Deployed in Azure VNet
- Private IP address
- Supports hybrid connectivity (VPN, ExpressRoute)
- Can join managed domain

#### Compatibility
- Near 100% compatibility with SQL Server
- Most SQL Server features supported
- Online migration tools available

### Service Tiers

#### General Purpose

**Cost-effective for most workloads**

**Characteristics**:
- Remote storage (Azure Premium Storage)
- 99.99% availability SLA
- Standard performance

**Pricing**:
- 4 vCores: ~$1,000/month
- 8 vCores: ~$2,000/month
- 16 vCores: ~$4,000/month

#### Business Critical

**High performance and availability**

**Characteristics**:
- Local SSD storage
- 99.99% availability SLA
- Built-in Always On Availability Group
- Free read replica

**Pricing**:
- 4 vCores: ~$2,500/month
- 8 vCores: ~$5,000/month
- 16 vCores: ~$10,000/month

### Use Cases

‚úÖ **Use SQL Managed Instance When**:
- Migrating from SQL Server on-premises
- Need instance-scoped features (SQL Agent, Service Broker)
- Cross-database queries required
- Need managed domain integration
- Lift-and-shift with minimal changes

‚ùå **Don't Use When**:
- Modern cloud-native application
- Don't need SQL Server specific features
- Cost is primary concern
- Simpler management preferred

## SQL Server on Azure VMs

**SQL Server on Azure Virtual Machines** provides full control over SQL Server and OS, running on IaaS infrastructure.

### Key Features

- Full SQL Server control
- Full OS control
- Any SQL Server version
- Flexible licensing (BYOL, PAYG)
- Custom extensions and configurations
- Windows or Linux

### VM Sizes and Pricing

#### Small (Development/Test)
- **Standard_D2s_v3**: 2 vCores, 8 GB RAM
- SQL Server Standard: ~$190/month
- SQL Server Enterprise: ~$515/month

#### Medium (Production)
- **Standard_D8s_v3**: 8 vCores, 32 GB RAM
- SQL Server Standard: ~$760/month
- SQL Server Enterprise: ~$2,060/month

#### Large (High Performance)
- **Standard_E16s_v3**: 16 vCores, 128 GB RAM
- SQL Server Standard: ~$1,950/month
- SQL Server Enterprise: ~$4,120/month

### Use Cases

‚úÖ **Use SQL Server on VMs When**:
- Need full SQL Server control
- Need OS-level access
- Custom SQL Server configuration required
- Specific SQL Server version needed
- Third-party tools requiring specific setup

‚ùå **Don't Use When**:
- Want minimal management overhead
- Don't need OS access
- Want automated patching/backups
- PaaS benefits desired

### Disk Caching Best Practices for SQL Server on Azure VMs

When configuring SQL Server on Azure VMs, proper disk caching configuration is critical for optimal performance and data integrity. Azure offers three host caching policies for managed disks:

#### Caching Options

| Caching Policy | Description | Use Case |
|----------------|-------------|----------|
| **None** | No caching | Write-intensive workloads, transaction logs |
| **ReadOnly** | Read caching only | Read-intensive workloads, data files |
| **ReadWrite** | Read and write caching | OS disks (not recommended for SQL) |

#### Recommended Configuration by Disk Type

| SQL Server Disk Type | Recommended Caching | Rationale |
|---------------------|--------------------|-----------|
| **Data disk** | **ReadOnly** | Improves read performance while maintaining data integrity. SQL Server workloads typically involve frequent read operations from data files. Enables faster retrieval from host cache. |
| **Transaction log disk** | **None** | No performance benefit for sequential write operations. Caching can degrade write performance and decrease available cache for data disk reads. |
| **Operating OS disk** | **ReadWrite** (default) | Default OS configuration is optimal. Not recommended to change. |
| **tempdb disk** | **ReadOnly** | If tempdb cannot fit on ephemeral drive (D:\), place on separate data disk with ReadOnly caching. |

#### Detailed Recommendations

**Data Disk (ReadOnly Caching)**:
- **Enable ReadOnly caching** for the disks hosting SQL Server data files
- Reads from cache will be faster than uncached reads from the data disk
- Uncached IOPS and throughput plus Cached IOPS and throughput yield the total possible performance available from the VM within the VM's limits
- Actual performance varies based on the workload's ability to use the cache (cache hit ratio)
- **Best for**: Read-intensive database operations, OLTP workloads

**Transaction Log Disk (None Caching)**:
- **Set the caching policy to None** for disks hosting the transaction log
- There's no performance benefit to enabling caching for the transaction log disk
- Having either ReadOnly or ReadWrite caching enabled on the log drive can degrade performance of the writes against the drive
- Caching reduces the amount of cache available for reads on the data drive
- **Best for**: Sequential write operations that don't benefit from caching

**Operating OS Disk (ReadWrite - Default)**:
- The default caching policy is **ReadWrite** for the OS drive
- **It is not recommended to change** the caching level of the OS drive
- Standard OS workloads benefit from the default configuration

**tempdb Configuration**:
- If tempdb **can't be placed on the ephemeral drive D:\** due to capacity reasons:
  - Either resize the VM to get a larger ephemeral drive
  - Or place tempdb on a separate data drive with **ReadOnly caching** configured
- The VM cache and ephemeral drive both use the local SSD
- Keep this in mind when sizing as tempdb I/O will count against the cached IOPS and throughput VM limits when hosted on the ephemeral drive

#### Performance Impact Examples

**Scenario 1: Data Disk with ReadOnly Caching (Optimal)**
```
P40 Disk: 7,500 IOPS, 250 MB/s
VM Cache: Additional cached reads
Result: Improved query performance for read operations
Cache Hit Ratio: 70% ‚Üí 70% of reads served from fast cache
```

**Scenario 2: Transaction Log with None Caching (Optimal)**
```
P40 Disk: 7,500 IOPS, 250 MB/s
No caching overhead
Result: Maximum write throughput for transaction log
Benefit: More cache available for data disk reads
```

**Scenario 3: Data Disk with ReadWrite Caching (Not Recommended)**
```
Risk: Data corruption during unexpected failures
Issue: Writes cached in host memory may be lost
Result: Unsuitable for transactional systems like SQL Server
```

#### Key Considerations

‚úÖ **Do**:
- Use ReadOnly caching for data disks to optimize read performance
- Use None caching for transaction log disks to optimize write performance
- Place tempdb on ephemeral drive (D:\) when possible for best performance
- Monitor cache hit ratios to validate effectiveness
- Use Premium SSD (P-series) or Ultra Disks for SQL Server workloads

‚ùå **Don't**:
- Use ReadWrite caching for SQL Server data or log disks (risk of data corruption)
- Enable any caching on transaction log disks (degrades performance)
- Change OS disk caching from default ReadWrite
- Place transaction log on the ephemeral drive (data loss risk on VM restart)

**Reference**: [SQL Server on Azure VMs - Storage Performance Best Practices](https://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage?view=azuresql#data-file-caching-policies)

## Pricing Tiers Comparison

### Single Database - General Purpose (Serverless vs Provisioned)

| Configuration | Provisioned | Serverless (50% active) |
|---------------|-------------|-------------------------|
| 2 vCores | $360/month | ~$90/month |
| 4 vCores | $720/month | ~$180/month |
| 8 vCores | $1,440/month | ~$360/month |

**Savings**: Up to 75% for intermittent workloads

### Cross-Product Comparison (8 vCores, General Purpose)

| Product | Monthly Cost | Management | Best For |
|---------|--------------|------------|----------|
| **SQL Database (Provisioned)** | ~$1,440 | Fully managed | Modern apps |
| **SQL Database (Serverless avg)** | ~$360 | Fully managed | Intermittent use |
| **SQL Managed Instance** | ~$2,000 | Fully managed | Migrations |
| **SQL VM (Standard)** | ~$760 | Self-managed | Full control |
| **SQL VM (Enterprise)** | ~$2,060 | Self-managed | Full control + features |

### Service Tier Comparison (SQL Database, 4 vCores)

| Tier | Monthly Cost | IOPS | Max Storage | Best For |
|------|--------------|------|-------------|----------|
| **General Purpose** | ~$720 | ~7,000 | 4 TB | Most workloads |
| **Business Critical** | ~$1,800 | ~200,000 | 4 TB | Mission-critical |
| **Hyperscale** | ~$1,000+ | Varies | 100 TB | Large databases |

## Feature Comparison

### Azure SQL Products Feature Matrix

| Feature | SQL Database | SQL Managed Instance | SQL on VMs |
|---------|--------------|---------------------|------------|
| **Management** | Fully managed | Fully managed | Self-managed |
| **SQL Compatibility** | ~95% | ~100% | 100% |
| **Auto-scaling** | ‚úÖ Serverless | ‚ùå | ‚ö†Ô∏è Manual |
| **Per-second billing** | ‚úÖ Serverless | ‚ùå | ‚ùå |
| **Elastic pools** | ‚úÖ | ‚úÖ Instance pools | ‚ùå |
| **VNet injection** | ‚ö†Ô∏è Private endpoint | ‚úÖ Native | ‚úÖ Native |
| **SQL Agent** | ‚ùå | ‚úÖ | ‚úÖ |
| **Cross-DB queries** | ‚ö†Ô∏è Elastic queries | ‚úÖ | ‚úÖ |
| **Linked servers** | ‚ùå | ‚úÖ Limited | ‚úÖ Full |
| **Service Broker** | ‚ùå | ‚úÖ | ‚úÖ |
| **CLR** | ‚ùå | ‚úÖ | ‚úÖ |
| **Backup control** | ‚ùå Automated | ‚ö†Ô∏è Limited | ‚úÖ Full |
| **Patching control** | ‚ùå Automated | ‚ùå Automated | ‚úÖ Full |
| **OS access** | ‚ùå | ‚ùå | ‚úÖ |
| **Max DB size** | 4 TB (100 TB Hyperscale) | 16 TB | Unlimited |
| **Geo-replication** | ‚úÖ Active | ‚úÖ Failover groups | ‚ö†Ô∏è Manual |

### Deployment Options Comparison

| Deployment | Resource Sharing | Scaling | Billing | Best For |
|------------|-----------------|---------|---------|----------|
| **Single Database** | Dedicated | Per database | Per database | Individual apps |
| **Elastic Pool** | Shared pool | Pool level | Per pool | Multi-tenant SaaS |
| **Managed Instance** | Instance | Instance level | Per instance | Instance migration |

## Decision Guide

### Question-Based Selection

#### Q1: Do you need full SQL Server and OS control?
- **YES** ‚Üí SQL Server on Azure VMs
- **NO** ‚Üí Continue to Q2

#### Q2: Do you need instance-scoped features (SQL Agent, Service Broker, cross-DB queries)?
- **YES** ‚Üí Azure SQL Managed Instance
- **NO** ‚Üí Continue to Q3

#### Q3: Is it a new cloud-native application?
- **YES** ‚Üí Azure SQL Database (Single or Elastic Pool)
- **NO** ‚Üí Continue to Q4

#### Q4: Do you have unpredictable or intermittent workload?
- **YES** ‚Üí Azure SQL Database (Serverless)
- **NO** ‚Üí Azure SQL Database (Provisioned)

#### Q5: Do you have multiple databases with varying usage?
- **YES** ‚Üí Azure SQL Database (Elastic Pool)
- **NO** ‚Üí Azure SQL Database (Single)

### Service Tier Selection (SQL Database)

#### Choose General Purpose when:
- ‚úÖ Standard business workload
- ‚úÖ Budget-conscious
- ‚úÖ Storage < 4 TB
- ‚úÖ Latency tolerance (5-10ms)

#### Choose Business Critical when:
- ‚úÖ Mission-critical application
- ‚úÖ Low latency required (<2ms)
- ‚úÖ High transaction rate
- ‚úÖ Need read replicas
- ‚úÖ Zone redundancy needed

#### Choose Hyperscale when:
- ‚úÖ Database > 4 TB
- ‚úÖ Need rapid scaling
- ‚úÖ Multiple read replicas needed
- ‚úÖ Fast backup/restore critical

### Compute Tier Selection

#### Choose Provisioned when:
- ‚úÖ Consistent 24/7 usage
- ‚úÖ Production workload
- ‚úÖ Predictable performance required
- ‚úÖ No tolerance for cold start delay

#### Choose Serverless when:
- ‚úÖ Development/test environments
- ‚úÖ Intermittent usage patterns
- ‚úÖ Cost optimization priority
- ‚úÖ Unpredictable workload
- ‚úÖ Can tolerate resume delay (seconds)

## Best Practices

### Cost Optimization

#### 1. Right-Size Resources
```
‚ùå Over-provisioned: 8 vCores, 20% avg CPU ‚Üí $1,440/month
‚úÖ Right-sized: 4 vCores, 60% avg CPU ‚Üí $720/month
Savings: $720/month (50%)
```

#### 2. Use Serverless for Dev/Test
```
‚ùå Provisioned 4 vCores 24/7 ‚Üí $720/month
‚úÖ Serverless 4 vCores, 8hr/day ‚Üí ~$180/month
Savings: $540/month (75%)
```

#### 3. Leverage Azure Hybrid Benefit
```
‚ùå Without Hybrid Benefit ‚Üí $720/month
‚úÖ With Hybrid Benefit (existing license) ‚Üí $207/month
Savings: $513/month (71%)
```

#### 4. Use Elastic Pools for Multiple DBs
```
‚ùå 10 databases √ó $360 each ‚Üí $3,600/month
‚úÖ Elastic pool for 10 databases ‚Üí $1,800/month
Savings: $1,800/month (50%)
```

#### 5. Reserved Capacity
```
‚ùå Pay-as-you-go: $720/month √ó 12 = $8,640/year
‚úÖ 1-year reserved: ~$6,500/year
‚úÖ 3-year reserved: ~$4,800/year
Savings: Up to 44%
```

### Performance Optimization

‚úÖ **Use appropriate indexes** - Reduces I/O and improves query performance  
‚úÖ **Enable automatic tuning** - AI-powered performance recommendations  
‚úÖ **Use query performance insights** - Identify slow queries  
‚úÖ **Scale up temporarily** - For known peak periods  
‚úÖ **Use read replicas** - Offload read workloads (Business Critical)  
‚úÖ **Implement connection pooling** - Reduce connection overhead  
‚úÖ **Monitor DTU/vCore usage** - Identify bottlenecks  

### High Availability

> üìñ **For detailed high availability and zone redundancy information**, see the [High Availability and Zone Redundancy](#high-availability-and-zone-redundancy) section above.

‚úÖ **Choose the right tier for your HA requirements**:
  - **Zero data loss required**: Premium (DTU) or Business Critical (vCore)
  - **Zone redundancy required**: Premium, General Purpose, Business Critical, or Hyperscale
  - **Cost optimization with HA**: Premium (DTU) offers best balance
  
‚úÖ **Enable zone-redundancy** - Protect against datacenter/zone failures  
‚úÖ **Enable geo-replication** - Disaster recovery across regions  
‚úÖ **Configure failover groups** - Automatic failover capability with zone redundancy
‚úÖ **Test failover procedures** - Ensure recovery processes work  
‚úÖ **Monitor backup status** - Verify backups are successful  
‚úÖ **Understand RPO/RTO requirements** - Select tier that meets objectives  

### Security Best Practices

‚úÖ **Enable Azure AD authentication** - Centralized identity management  
‚úÖ **Use private endpoints** - Eliminate public internet exposure  
‚úÖ **Enable Transparent Data Encryption (TDE)** - Encrypt data at rest  
‚úÖ **Use Always Encrypted** - Protect sensitive data  
‚úÖ **Enable Advanced Threat Protection** - Detect anomalous activities  
‚úÖ **Implement row-level security** - Fine-grained access control  
‚úÖ **Enable auditing** - Track database activities  
‚úÖ **Regular security assessments** - Identify vulnerabilities

#### Azure SQL Database Auditing

**Azure SQL Database Auditing** tracks database events and writes them to an audit log. It helps maintain regulatory compliance, understand database activity, and gain insights into potential security violations.

**Key Requirements and Constraints**:

1. **Regional Constraint for Storage Accounts**
   - The storage account used for storing audit logs **must be in the same region** as the SQL server
   - Example: If your SQL server is in East US, the storage account must also be in East US
   - Cross-region storage is not supported for audit log storage

2. **Service Tier Support**
   - Auditing is supported across all service tiers (Basic, Standard, Premium)
   - Available for all purchasing models (DTU-based and vCore-based)

3. **Storage Options**
   - **Azure Storage Account**: Store audit logs in blob storage
   - **Log Analytics Workspace**: Integrate with Azure Monitor for advanced querying
   - **Event Hub**: Stream audit logs to SIEM tools or external systems

4. **Audit Scope**
   - Database-level auditing: Applies to a specific database
   - Server-level auditing: Applies to all databases on the server

**Example Scenario**:

Given the following Azure resources:

| Resource | Type | Region | Details |
|----------|------|--------|---------|
| SQLsvr1 | SQL Server | East US | - |
| SQLsvr2 | SQL Server | West US | - |
| SQLdb1 | SQL Database | East US | Standard tier on SQLsvr1 |
| SQLdb2 | SQL Database | East US | Standard tier on SQLsvr1 |
| SQLdb3 | SQL Database | West US | Premium tier on SQLsvr2 |
| storage1 | Storage Account | East US | StorageV2 |
| storage2 | Storage Account | Central US | BlobStorage |

**Auditing Compatibility**:
- ‚úÖ SQLdb1 ‚Üí storage1: **Supported** (same region: East US)
- ‚úÖ SQLdb2 ‚Üí storage1: **Supported** (same region: East US)
- ‚ùå SQLdb1 ‚Üí storage2: **Not supported** (different regions: East US vs Central US)
- ‚ùå SQLdb3 ‚Üí storage1: **Not supported** (different regions: West US vs East US)

**Best Practices**:
- Enable auditing at the server level to audit all databases automatically
- Use Log Analytics for long-term retention and advanced analysis
- Configure retention policies based on compliance requirements
- Monitor audit logs regularly for suspicious activities

**Reference**: [Azure SQL Database Auditing Overview](https://learn.microsoft.com/azure/azure-sql/database/auditing-overview)  

### Migration to Azure SQL

For comprehensive information about migrating SQL Server databases to Azure, including detailed tool comparisons, best practices, and step-by-step workflows, see the dedicated **[Azure SQL Migration Guide](./azure-sql-migration-guide.md)**.

**Quick Migration Tool Reference**:

| Your Requirement | Recommended Tool |
|------------------|------------------|
| **Offline migration + Minimize admin effort** | Azure Database Migration Service |
| **Online migration + Minimize downtime** | Azure Data Studio (with Azure SQL Migration extension) |
| **Assessment before migration** | Azure Migrate or Data Migration Assistant |
| **Migrating from Oracle/MySQL** | SQL Server Migration Assistant |

For detailed explanations, real-world scenarios, and migration workflows, refer to the [Azure SQL Migration Guide](./azure-sql-migration-guide.md).

### Migration Tools Comparison (Quick Summary)

**Azure Database Migration Service (DMS)**: Fully managed service for offline migrations with minimal administrative effort. Best for large-scale migrations (50+ databases).

**Azure Data Studio**: Cross-platform tool with Azure SQL Migration extension for online migrations with minimal downtime. Ideal for production databases requiring continuous availability.

**Azure Migrate**: Assessment and discovery platform for migration planning, cost estimation, and compatibility analysis.

**Data Migration Assistant (DMA)**: Assessment-only tool for identifying compatibility issues before migration.

**SQL Server Migration Assistant (SSMA)**: For heterogeneous migrations from Oracle, MySQL, DB2 to SQL Server/Azure SQL.

> üìö **For detailed tool comparisons, workflows, and real-world scenarios, see the [Azure SQL Migration Guide](./azure-sql-migration-guide.md)**

## Common Scenarios and Recommendations

### Scenario 1: New Modern Web Application
**Requirements**: Auto-scaling, cost optimization, simple management

**Recommendation**: 
- **Azure SQL Database** (Single Database)
- **Serverless** compute tier
- **General Purpose** service tier

**Why**: Modern cloud-native design, per-second billing, auto-scaling, minimal management

### Scenario 2: Multi-Tenant SaaS Application
**Requirements**: Multiple databases, cost efficiency, varying usage patterns

**Recommendation**:
- **Azure SQL Database** (Elastic Pool)
- **Provisioned** compute tier
- **General Purpose** service tier

**Why**: Resource sharing across tenants, cost-effective, pool-level management

### Scenario 3: Migrating SQL Server Enterprise
**Requirements**: Minimal code changes, SQL Agent, cross-database queries

**Recommendation**:
- **Azure SQL Managed Instance**
- **General Purpose** service tier

**Why**: Near 100% SQL Server compatibility, instance-scoped features, lift-and-shift

### Scenario 4: Mission-Critical OLTP Application
**Requirements**: Low latency, high availability, read scale-out

**Recommendation**:
- **Azure SQL Database** (Single Database)
- **Provisioned** compute tier
- **Business Critical** service tier
- **Zone redundancy** enabled

**Why**: <2ms latency, local SSD, built-in read replica, 99.995% SLA

### Scenario 5: Large Data Warehouse
**Requirements**: 10 TB database, multiple read workloads, fast scaling

**Recommendation**:
- **Azure SQL Database** (Hyperscale)
- **Provisioned** compute tier
- **4 read replicas**

**Why**: Up to 100 TB storage, fast scaling, multiple read replicas, cost-effective for large DBs

### Scenario 6: Development and Test Environment
**Requirements**: Used 8 hours/day, cost optimization, temporary databases

**Recommendation**:
- **Azure SQL Database** (Single Database)
- **Serverless** compute tier (0.5-4 vCores)
- **General Purpose** service tier
- **Auto-pause enabled** (60 min)

**Why**: Up to 80% cost savings, pay per second of use, auto-pause during inactivity

### Scenario 7: Enterprise Migration with High Resiliency Requirements (Litware Inc. Case Study)
**Requirements**: 
- Migrating on-premises databases (DB1 and DB2) to Azure
- Must maintain availability if two availability zones in the region fail
- Minimal I/O latency for optimal performance
- Minimal administrative effort and operational complexity
- Near 100% SQL Server feature compatibility
- Support for advanced features like automatic failover and geo-replication

**Recommendation**:
- **Azure SQL Managed Instance**
- **Business Critical** service tier (for optimal I/O latency)
- **Zone-redundant configuration** enabled
- **Geo-replication** for disaster recovery

**Why**: 
- **Resiliency**: Azure SQL Managed Instance supports zone-redundant configuration and automatic failover, ensuring availability even if two availability zones fail. Geo-replication provides additional disaster recovery capabilities.
- **Performance**: Business Critical tier uses local SSD storage, delivering minimal I/O latency required for DB1 and DB2.
- **Minimal Administrative Effort**: As a fully managed PaaS service, it offloads tasks such as automated backups, patching, and high availability setup, significantly reducing operational complexity.
- **SQL Server Compatibility**: Near 100% compatibility with on-premises SQL Server Enterprise Edition, allowing lift-and-shift migrations with minimal code changes.
- **Advanced Features**: Supports enterprise-grade capabilities like SQL Server Agent, Service Broker, cross-database queries, and distributed transactions.

**Why Other Options Are Incorrect**:
- **Single Azure SQL Database**: While it can be made zone-redundant in premium tiers, it lacks the broad SQL Server feature compatibility and enterprise-grade scalability required for complex workloads like DB1 and DB2. It's best suited for standalone or less complex databases.
- **Azure SQL Database Elastic Pool**: Designed for managing multiple databases with varying usage patterns in a cost-effective manner. It does not offer the resiliency features (zone redundancy across multiple zones) or low-latency performance needed for mission-critical databases that must remain available during zone failures.

**Reference Links**:
- [Azure SQL High Availability SLA](https://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla)
- [Azure SQL Managed Instance PaaS Overview](https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview?view=azuresql)

### Scenario 8: Multiple Databases with Varying Usage Patterns
**Requirements**: 
- 20 databases that will be 20 GB each
- Varying usage patterns across databases
- 99.99% uptime SLA
- Dynamic compute resource scaling
- Reserved capacity support
- Minimize compute charges

**Recommendation**:
- **Azure SQL Database Elastic Pool**
- **General Purpose** service tier (or higher as needed)
- **vCore-based** purchasing model (for reserved capacity)
- Pool size configured based on aggregate usage patterns

**Why**: 
- **Resource Sharing**: Elastic pools allow multiple databases to share a pool of compute and storage resources, making them ideal for scenarios with varying usage patterns across databases. Databases can consume resources as needed from the shared pool, optimizing cost efficiency.
- **99.99% SLA**: Built-in high availability meets the uptime requirement.
- **Dynamic Scaling**: Elastic pools can automatically scale compute within the pool based on actual usage, addressing the need for dynamic resource allocation.
- **Reserved Capacity**: Supports reserved capacity through the vCore purchasing model, providing cost savings for predictable workloads.
- **Cost Minimization**: Pooling resources instead of provisioning separate resources for each database significantly reduces compute charges, especially when databases have complementary usage patterns (when some databases are busy, others may be idle).

**Why Other Options Are Incorrect**:
- **20 databases on a Microsoft SQL server on an Azure VM in an availability set**: While this provides control and high availability through availability sets, it does not support dynamic compute scaling and typically results in higher operational overhead and cost compared to PaaS offerings like Azure SQL. It also requires manual management of infrastructure, which goes against the goal of minimizing compute charges and ensuring simplicity.
- **20 instances of Azure SQL Database serverless**: Although serverless can scale compute automatically and pause during inactivity to save costs, it does NOT support reserved capacity pricing, which is a requirement in this scenario. Serverless is best suited for intermittent workloads but not when reserved compute capacity is needed. Additionally, managing 20 separate serverless databases would be more complex and potentially more expensive than using a single elastic pool.
- **20 databases on Microsoft SQL server on an Azure VM**: This option lacks dynamic scaling capabilities, does not support reserved PaaS-level pricing benefits, and requires managing infrastructure. This violates the requirement to minimize compute charges and ensure operational simplicity.

**Reference Links**:
- [Elastic Pool Overview](https://learn.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview)
- [Azure SQL Database Reserved Capacity](https://learn.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview)
- [Serverless Tier Overview](https://learn.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview)

### Scenario 9: SQL Server VM Storage Configuration
**Requirements**: 
- Virtual machine running Microsoft SQL Server
- Two P40 managed disks: one for log files, one for data files
- Need best overall performance
- Must preserve integrity of SQL data and logs

**Recommendation**:
- **SQL Server on Azure VM** (IaaS)
- **Data disk**: ReadOnly host caching
- **Transaction log disk**: None host caching
- **Premium SSD** (P40) managed disks

**Why**: 
- **Data Disk (ReadOnly Caching)**: Offers performance benefits through host caching while maintaining data integrity. SQL Server workloads typically involve frequent read operations from data files. Enabling ReadOnly caching allows Azure to cache data in the host machine's memory for faster retrieval, improving overall read performance. This setting is commonly recommended by Microsoft for SQL Server data disks as it optimizes read-intensive operations without risking corruption or integrity issues. Reads from cache will be faster than uncached reads, and the cache hit ratio determines actual performance gains.

- **Transaction Log Disk (None Caching)**: Disables host caching completely for optimal write performance. While it's safe in terms of data integrity, sequential write operations to transaction logs don't benefit from caching. In fact, enabling caching on transaction log disks can degrade performance of writes and decrease the amount of cache available for reads on the data drive. Setting caching to None ensures maximum throughput for transaction log writes and preserves cache resources for data disk operations.

**Why Other Options Are Incorrect**:
- **None caching for data disk**: While safe for data integrity, it results in slower read performance for database queries that access data files frequently. This doesn't provide the best overall performance, even though it maintains integrity.

- **ReadWrite caching for data disk**: Introduces the risk of data corruption, especially with transactional systems like SQL Server. Caching writes in host memory can lead to data loss during unexpected failures (such as VM crashes or power outages), making it unsuitable for SQL data or log disks where write consistency and durability are critical. This violates the requirement to preserve data integrity.

- **ReadOnly or ReadWrite caching for transaction log disk**: Provides no performance benefit for sequential write operations characteristic of transaction logs. Can actually degrade write performance and reduce available cache for data disk reads.

**Performance Impact**:
- Data disk with ReadOnly: Faster query performance for read-heavy workloads
- Transaction log with None: Maximum write throughput, no caching overhead
- Combined configuration: Optimal balance of read and write performance
- Cache hit ratio of 70%+ on data disk provides significant performance gains

**Reference Links**:
- [SQL Server on Azure VMs - Storage Performance Best Practices](https://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage?view=azuresql#data-file-caching-policies)
- [Azure Managed Disks - Host Caching](https://learn.microsoft.com/en-us/azure/virtual-machines/premium-storage-performance#disk-caching)

---

### Scenario 10: Intermittent Monthly Workload Migration
**Requirements**: 
- Migrate on-premises SQL Server databases to Azure with the following sizes:

| Name | Storage |
|------|---------|
| DB1  | 450 GB  |
| DB2  | 250 GB  |
| DB3  | 300 GB  |
| DB4  | 50 GB   |
| **Total** | **1,050 GB** |

- Application and data used only on the first day of each month
- Data growth expected to be less than 3% annually
- Need to minimize costs while ensuring database availability for monthly usage

**Recommendation**:
- **Azure SQL Database** (Single Database)
- **vCore-based General Purpose** service tier
- **Serverless** compute tier
- Auto-pause delay configured appropriately (e.g., 1-2 hours after inactivity)

**Why**: 
- **Serverless Compute with Auto-Pause**: The serverless compute tier supports automatic pausing and resuming of the database based on activity. Since the requirement specifies the database is only used on the first day of each month, the serverless capability enables the database to be paused for the remaining ~29 days, significantly reducing costs. During the paused state, you're only billed for storage, not compute, which aligns perfectly with the intermittent usage pattern.
- **Cost Optimization**: With serverless, you can save up to 80% compared to provisioned compute for intermittent workloads. The database automatically resumes when accessed on the first day of the month and pauses again after the configured inactivity period.
- **Scalability**: General Purpose with serverless can handle the database size requirements (supports up to 4 TB) and the minimal annual growth of 3%.
- **Per-Second Billing**: You only pay for compute resources when the database is active, making it ideal for monthly usage patterns.

**Cost Example**:
```
Active usage: 1 day/month (~24 hours)
Paused: 29 days/month
Average compute: 4 vCores during active time

Compute cost: 24 hours √ó 4 vCores √ó ~$0.20/vCore-hour = ~$19.20/month
Storage cost (1 TB): 1024 GB √ó $0.12/GB = ~$122.88/month
Total: ~$142/month (vs ~$720/month with provisioned compute)
```

**Why Other Options Are Incorrect**:
- **DTU-based Basic**: Incorrect because it supports databases only up to 2 GB in size, whereas the combined database size from the scenario exceeds 1 TB. This tier cannot accommodate the storage requirements.
- **DTU-based Standard**: Incorrect because although it supports larger database sizes (up to 1 TB per database), DTUs are always provisioned and billed regardless of actual usage. Since the app is only used once a month, this model would result in paying for 29 days of unused compute resources, leading to unnecessary costs. DTU-based models do not support the serverless auto-pause capability.
- **vCore-based Business Critical**: Incorrect because it is designed for mission-critical applications requiring the highest performance, lowest latency (<2ms), and built-in high availability through multiple replicas. The scenario does not indicate the need for such performance or availability requirements. Additionally, Business Critical does not support the serverless compute tier, making it unable to pause during inactive periods. This tier would be unnecessarily expensive for an intermittent monthly workload.

**Key Considerations**:
- **Auto-Pause Configuration**: Set an appropriate auto-pause delay (1-2 hours) to ensure the database pauses after completion of monthly processing
- **Resume Time**: First connection after pause will have a brief delay (few seconds) while the database resumes
- **Serverless Availability**: Only available in General Purpose tier, not Business Critical
- **Storage Billing**: Storage is billed continuously even when paused, but at a much lower rate than compute

**Reference Links**:
- [Azure SQL Database Serverless Tier Overview](https://learn.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview?view=azuresql&tabs=general-purpose)
- [Azure SQL Database General Purpose Service Tier](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tier-general-purpose)
- [Azure SQL Database DTU Service Tiers](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-dtu)
- [Azure SQL Database DTU Resource Limits](https://learn.microsoft.com/en-us/azure/azure-sql/database/resource-limits-dtu-single-databases?view=azuresql)

**Domain**: Design data storage solutions

---

### Scenario 11: Data Warehouse for Reporting with High Concurrent Read Operations
**Requirements**: 
- Design a data storage solution to support reporting
- Ingest high volumes of JSON data using Azure Event Hubs
- Data organized in directories by date and time
- Stored data must be queryable directly, transformed into summarized tables, and stored in a data warehouse
- Data warehouse must store **50 TB of relational data**
- Support **200-300 concurrent read operations**

**Recommendation**:
- **Azure SQL Database Hyperscale** for the data warehouse

**Why**: 
- **Large-Scale Storage**: Azure SQL Database Hyperscale is specifically designed to handle large relational datasets, supporting up to **100 TB of storage**, which comfortably accommodates the 50 TB requirement.
- **Independent Compute and Storage Scaling**: Hyperscale offers flexibility and cost efficiency by allowing compute and storage to scale independently, which is ideal for workloads with varying read demands.
- **High Concurrent Read Support**: The Hyperscale tier can handle 200-300 concurrent read operations efficiently, making it suitable for enterprise-grade reporting workloads.
- **High Performance**: Delivers fast backups and high performance, suitable for enterprise-grade data workloads.

**Why Other Options Are Incorrect**:
- **Azure Cosmos DB Cassandra API**: Incorrect because it is intended for NoSQL column-family workloads and not designed for storing or querying large volumes of relational, structured data. It does not support analytical queries efficiently and is not cost-effective for 50 TB data storage.
- **Azure Cosmos DB SQL API**: Incorrect because although it supports JSON-based document storage with flexible schema, it is not a relational database and is unsuitable for warehouse-scale storage or complex SQL-based analytics at the scale described.
- **Azure Synapse Analytics dedicated SQL pools**: Incorrect in this context because while it is designed for large-scale analytical processing, it is more suitable when working with pre-aggregated or summarized data from a data lake rather than being used as a primary data warehouse for high-volume relational storage with frequent concurrent read access. When relational consistency, transactional support, and high concurrent access are required, Hyperscale is more appropriate.

**Architecture Pattern**:
```
Azure Event Hubs (JSON ingestion) 
    ‚Üí Azure Data Lake Storage (organized by date/time directories)
    ‚Üí Data transformation (Azure Data Factory / Databricks)
    ‚Üí Azure SQL Database Hyperscale (data warehouse for reporting)
```

**Reference Links**:
- [Azure SQL Database Hyperscale](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale?view=azuresql)
- [Azure SQL Managed Instance Resource Limits](https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/resource-limits?view=azuresql)
- [Azure Cosmos DB Introduction](https://learn.microsoft.com/en-us/azure/cosmos-db/introduction)
- [Azure Synapse Analytics Compute Management](https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-manage-compute-overview)

**Domain**: Design data storage solutions

---

### Scenario 12: Large-Scale Database Deployment with License Mobility
**Requirements**: 
- Deploy 50 databases to Azure
- Microsoft Volume Licensing customer with License Mobility through Software Assurance
- Support automatic scaling
- Minimize Microsoft SQL Server licensing costs

**Recommendation**:
- **Azure SQL Database** with **vCore-based** purchasing model
- **General Purpose** or **Business Critical** service tier (based on performance needs)
- **Serverless** compute tier (for automatic scaling requirements)
- **Azure Hybrid Benefit** enabled (to leverage existing licenses)

**Why**: 
- **License Mobility Support**: The vCore (virtual core) purchase model in Azure SQL Database supports License Mobility through Software Assurance. Since the customer is a Microsoft Volume Licensing customer participating in Software Assurance, they are eligible for the **Azure Hybrid Benefit**, allowing them to bring their own SQL Server licenses to Azure and significantly reduce SQL licensing costs (up to 55% savings on compute costs).
- **Automatic Scaling**: The vCore model supports automatic scaling through the serverless compute tier, which automatically scales compute based on workload demand and can pause during periods of inactivity.
- **Transparent Resource Control**: The vCore model offers transparent control over compute, memory, and I/O resources, making it ideal for deploying and managing a large number of databases efficiently.
- **Cost Optimization**: Combining Azure Hybrid Benefit with reserved capacity can provide up to 80% savings compared to pay-as-you-go pricing.

**Why Other Options Are Incorrect**:
- **DTU (Database Transaction Unit) model**: Incorrect because the DTU model is a bundled compute model with less flexibility. It **does not support Azure Hybrid Benefit or License Mobility through Software Assurance**, and it lacks detailed visibility and control over resource consumption. This leads to higher licensing costs for customers eligible for bring-your-own-license (BYOL) models.
- **Azure reserved virtual machine instances**: Incorrect because while reserved VM instances help reduce costs for SQL Server on Azure VMs, they apply to **IaaS-based deployments**, not PaaS-based Azure SQL Databases. Additionally, managing 50 databases on VMs would significantly increase operational overhead and not support automatic scaling as efficiently as the PaaS model under vCore.

**Azure Hybrid Benefit Savings Example**:
```
Without Azure Hybrid Benefit (Pay-as-you-go):
50 databases √ó 4 vCores √ó $720/month = $36,000/month

With Azure Hybrid Benefit (BYOL):
50 databases √ó 4 vCores √ó $324/month = $16,200/month

Savings: $19,800/month (55%)

With Azure Hybrid Benefit + 3-year Reserved Capacity:
50 databases √ó 4 vCores √ó $145/month = $7,250/month

Total Savings: $28,750/month (80%)
```

**Key Considerations**:
- ‚úÖ vCore model is required for Azure Hybrid Benefit
- ‚úÖ License Mobility allows using existing SQL Server licenses in Azure
- ‚úÖ Serverless tier provides automatic scaling within vCore model
- ‚úÖ Elastic pools can further optimize costs for 50 databases with varying usage
- ‚ùå DTU model does not support Azure Hybrid Benefit
- ‚ùå Azure VMs increase operational overhead compared to PaaS

**Reference Links**:
- [vCore-based Purchasing Model](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-sql-database-vcore?view=azuresql)
- [Azure SQL Database Purchasing Models](https://learn.microsoft.com/en-us/azure/azure-sql/database/purchasing-models?view=azuresql)
- [Azure Hybrid Benefit for Azure SQL](https://learn.microsoft.com/en-us/azure/azure-sql/azure-hybrid-benefit?view=azuresql)
- [Azure SQL Database Reserved Capacity](https://learn.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview)

**Domain**: Design data storage solutions

---

## Exam Practice Questions

### Question 1: Enterprise Database Migration with Resiliency Requirements (Litware Inc.)

**Scenario**: Refer to the Litware Inc. case study. You plan to migrate DB1 and DB2 to Azure. You need to ensure that the Azure database and the service tier meet the resiliency and business requirements.

**Question**: What should you configure for the Database?

**Options**:
- A) A single Azure SQL database
- B) Azure SQL managed instance
- C) An Azure SQL Database elastic pool

**Correct Answer**: **B) Azure SQL managed instance**

**Explanation**:

Azure SQL managed instance is correct because it allows you to bring your on-premises SQL Server databases to Azure with minimal administrative effort while maintaining high compatibility with existing SQL Server features. It supports advanced capabilities like automatic failover, zone-redundant configuration, and geo-replication, which satisfy the requirement to maintain availability if two availability zones in the region fail. Additionally, it is optimized for minimal I/O latency, meeting the performance expectations of DB1 and DB2. As a fully managed service, it also offloads tasks such as backups, patching, and high availability setup, directly supporting the business requirement to minimize both administrative effort and operational complexity.

**Why Other Options Are Incorrect**:

**A single Azure SQL database** is incorrect because it is best suited for standalone or less complex databases and may not support all SQL Server features. While it can be made zone-redundant in premium tiers, it lacks the broad feature compatibility and scalability required for enterprise-grade workloads like DB1 and DB2.

**An Azure SQL Database elastic pool** is incorrect because it is designed to manage multiple databases with varying usage patterns in a cost-effective manner. It does not offer the resiliency features or low-latency performance needed for critical databases that must remain available and performant during zone failures.

**Reference Links**:
- [Azure SQL High Availability SLA](https://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla)
- [Azure SQL Managed Instance PaaS Overview](https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview?view=azuresql)

**Domain**: Design data storage solutions

---

### Question 2: Service Tier Selection for High-Availability Requirements (Litware Inc.)

**Scenario**: Refer to the Litware Inc. case study. You plan to migrate DB1 and DB2 to Azure. You need to ensure that the Azure database and the service tier meet the resiliency and business requirements.

**Question**: What should you configure for the Service tier?

**Options**:
- A) Hyperscale
- B) Business Critical
- C) General Purpose

**Correct Answer**: **B) Business Critical**

**Explanation**:

**Business Critical** is correct because it is the only tier that meets all three resiliency requirements specified in the case study: 
1. Maintain availability even if two availability zones fail
2. Fail over automatically
3. Minimize I/O latency

The Business Critical tier is built for high-performance transactional workloads and provides zone-redundant configurations through synchronous replication across availability zones. It also uses local SSD-based storage, which ensures low latency and high throughput. Furthermore, since it is a platform-as-a-service (PaaS) offering, it also meets the requirement to minimize administrative effort.

**Why Other Options Are Incorrect**:

**General Purpose** is incorrect because although it offers zone redundancy, it relies on remote storage, which introduces higher I/O latency and lower throughput. This violates the requirement to minimize I/O latency. Additionally, the resiliency through zone redundancy in this tier is not generally available in all regions, making it less reliable for mission-critical workloads that demand proven zone failure resilience.

**Hyperscale** is incorrect because it is designed for extremely large databases and scale-out read scenarios, not high-availability transactional systems. Importantly, Hyperscale does not currently support zone redundancy, so it cannot meet the requirement to maintain availability if two availability zones fail, making it an unsuitable choice in this scenario.

**Reference Links**:
- [Azure SQL Database Service Tiers - When to Choose Business Critical](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-sql-database-vcore?view=azuresql#when-to-choose-this-service-tier-1)
- [Azure SQL High Availability SLA](https://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla)

**Domain**: Design data storage solutions

---

### Question 3: Azure SQL Database Auditing Storage Requirements

**Scenario**: You have an Azure subscription that contains the following resources:

**SQL Servers**:
| Name | Resource Group | Location |
|------|----------------|----------|
| SQLsvr1 | RG1 | East US |
| SQLsvr2 | RG2 | West US |

**Storage Accounts**:
| Name | Resource Group | Location | Account Kind |
|------|----------------|----------|--------------|
| storage1 | RG1 | East US | StorageV2 (general purpose v2) |
| storage2 | RG2 | Central US | BlobStorage |

**Azure SQL Databases**:
| Name | Resource Group | Server | Pricing Tier |
|------|----------------|--------|--------------|
| SQLdb1 | RG1 | SQLsvr1 | Standard |
| SQLdb2 | RG1 | SQLsvr1 | Standard |
| SQLdb3 | RG2 | SQLsvr2 | Premium |

**Question**: When you enable auditing for SQLdb1, can you store the audit information to storage1?

**Options**:
- A) Yes
- B) No

**Correct Answer**: **A) Yes**

**Explanation**:

Yes is correct because SQLdb1 is a Standard tier Azure SQL Database hosted on SQLsvr1, which is deployed in the East US region. The target storage account storage1 is also located in East US, which meets the requirement for storing audit logs ‚Äî **the storage account must be in the same region as the SQL server**.

Additionally, SQL auditing is supported for databases in the Standard tier, and since both the database and the storage account reside in the same region, storing audit logs from SQLdb1 to storage1 is fully supported.

**Key Requirements for Azure SQL Database Auditing**:
1. ‚úÖ Storage account must be in the **same region** as the SQL server
2. ‚úÖ Auditing is supported across **all service tiers** (Basic, Standard, Premium)
3. ‚úÖ Both DTU-based and vCore-based purchasing models support auditing

**Analysis of the Scenario**:
- SQLdb1 is on SQLsvr1 (East US) ‚Üí storage1 (East US): ‚úÖ **Supported** (same region)
- SQLdb1 is on SQLsvr1 (East US) ‚Üí storage2 (Central US): ‚ùå **Not supported** (different regions)
- SQLdb3 is on SQLsvr2 (West US) ‚Üí storage1 (East US): ‚ùå **Not supported** (different regions)

**Reference**: [Azure SQL Database Auditing Overview](https://learn.microsoft.com/azure/azure-sql/database/auditing-overview)

**Domain**: Design data storage solutions

---

### Question 4: Elastic Pool for Multiple Databases with Varying Usage

**Scenario**: You are designing a SQL database solution. The solution will include 20 databases that will be 20 GB each and have varying usage patterns.

**Requirements**:
- The solution must meet a Service Level Agreement (SLA) of 99.99% uptime
- The compute resources allocated to the databases must scale dynamically
- The solution must have reserved capacity
- Compute charges must be minimized

**Question**: What should you include in the recommendation?

**Options**:
- A) An elastic pool that contains 20 Azure SQL databases
- B) 20 databases on a Microsoft SQL server that runs on an Azure virtual machine in an availability set
- C) 20 instances of Azure SQL Database serverless
- D) 20 databases on Microsoft SQL server that runs on an Azure virtual machine

**Correct Answer**: **A) An elastic pool that contains 20 Azure SQL databases**

**Explanation**:

**An elastic pool that contains 20 Azure SQL databases** is correct because it allows multiple Azure SQL databases to share a pool of compute and storage resources, making it ideal for scenarios with varying usage patterns across databases. Elastic pools provide built-in high availability with a 99.99% SLA, support reserved capacity through vCore purchasing models, and help minimize compute charges by pooling resources instead of provisioning separate resources for each database. Additionally, elastic pools can automatically scale compute within the pool, addressing the need for dynamic resource usage. When some databases in the pool are experiencing high demand, they can consume more resources, while idle databases use minimal resources, resulting in optimal cost efficiency.

**Why Other Options Are Incorrect**:

**20 databases on a Microsoft SQL server that runs on an Azure virtual machine in an availability set** is incorrect because while it gives you full control and high availability through availability sets, it does not support dynamic compute scaling and typically results in higher operational overhead and cost compared to PaaS offerings like Azure SQL. Managing SQL Server on VMs requires infrastructure management, patching, and maintenance, which increases complexity and cost.

**20 instances of Azure SQL Database serverless** is incorrect because although serverless can scale compute automatically and pause during inactivity to save costs, it does **not support reserved capacity pricing**, which is required in this scenario. Serverless is best suited for intermittent workloads but not when reserved compute is needed. Additionally, provisioning 20 separate serverless databases would lack the cost efficiency of a shared resource pool and could result in higher overall costs compared to an elastic pool.

**20 databases on Microsoft SQL server that runs on an Azure virtual machine** is incorrect for similar reasons. Although it provides control and compatibility, it lacks dynamic scaling, reserved PaaS-level pricing benefits, and requires managing infrastructure, which goes against the goal of minimizing compute charges and ensuring simplicity. You would need to manually scale VMs and manage all operational aspects.

**Key Advantages of Elastic Pools**:
- ‚úÖ Share resources across multiple databases with varying patterns
- ‚úÖ Built-in 99.99% SLA for high availability
- ‚úÖ Dynamic scaling at the pool level
- ‚úÖ Supports reserved capacity with vCore model
- ‚úÖ Significantly lower cost than individual databases
- ‚úÖ Minimal administrative overhead (fully managed PaaS)

**Reference Links**:
- [Elastic Pool Overview](https://learn.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview)
- [Azure SQL Database Reserved Capacity](https://learn.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview)
- [Serverless Tier Overview](https://learn.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview)

**Domain**: Design data storage solutions

---

### Question 5: SQL Server on Azure VM Disk Caching Configuration

**Scenario**: You are designing a virtual machine that will run Microsoft SQL Server and will contain two data disks. The first data disk will store log files, and the second data disk will store data. Both disks are P40 managed disks.

**Requirements**:
- Provide the best overall performance for the virtual machine
- Preserve integrity of the SQL data and logs

**Question**: Which host caching method should you recommend for the **Data disk**?

**Options**:
- A) None
- B) ReadOnly
- C) ReadWrite

**Correct Answer**: **B) ReadOnly**

**Explanation**:

**ReadOnly** is correct for the data disk because it offers performance benefits through host caching while maintaining data integrity. SQL Server workloads typically involve frequent read operations from data files. Enabling ReadOnly caching allows Azure to cache data in the host machine's memory for faster retrieval, improving overall read performance. This setting is commonly recommended by Microsoft for SQL Server data disks as it optimizes read-intensive operations without risking corruption or integrity issues.

**How ReadOnly Caching Works**:
- Reads are cached in the host machine's memory (faster access)
- Writes bypass the cache and go directly to disk (maintains integrity)
- Uncached IOPS and throughput **plus** Cached IOPS and throughput yield the total possible performance
- Actual performance varies based on the workload's cache hit ratio
- Typical cache hit ratios of 60-80% provide significant performance improvements

**Why Other Options Are Incorrect**:

**None** is incorrect because it disables host caching completely, resulting in slower read performance for database queries that access data files frequently. While it's safe in terms of data integrity, it doesn't provide the **best performance**. All read operations must go directly to the disk, missing out on the performance benefits of host-level caching.

**ReadWrite** is incorrect because it introduces the **risk of data corruption**, especially with transactional systems like SQL Server. Caching writes in host memory can lead to data loss during unexpected failures (such as VM crashes, host failures, or power outages), making it unsuitable for SQL data or log disks where write consistency and durability are critical. Even though it might seem to offer better performance, it violates the requirement to **preserve integrity** of the SQL data.

**Additional Context - Transaction Log Disk Recommendation**:

For the **Transaction log disk** in this scenario, the correct answer would be **None**:
- Set the caching policy to **None** for disks hosting the transaction log
- There's no performance benefit to enabling caching for transaction log disks (sequential writes don't benefit from caching)
- Having either ReadOnly or ReadWrite caching enabled on the log drive can **degrade performance** of the writes against the drive
- Caching also decreases the amount of cache available for reads on the data drive

**Complete Recommended Configuration**:

| Disk Type | Caching Policy | Reason |
|-----------|----------------|--------|
| **Data disk** | **ReadOnly** | Optimizes read performance, maintains integrity |
| **Transaction log disk** | **None** | Optimizes write performance, no caching benefit |
| **OS disk** | **ReadWrite** (default) | Don't change from default |
| **tempdb disk** | **ReadOnly** or **Ephemeral (D:\)** | Fast local storage |

**Performance Example**:
```
P40 Premium SSD Specifications:
- 7,500 IOPS (uncached)
- 250 MB/s throughput (uncached)

With ReadOnly Caching on Data Disk:
- 7,500 IOPS (uncached) + additional cached IOPS from host
- Cache hit ratio of 70% = 70% of reads served from fast host cache
- Result: Significantly improved query performance

With None Caching on Transaction Log Disk:
- 7,500 IOPS for sequential writes
- No caching overhead
- Maximum write throughput maintained
```

**Key Takeaways**:
- ‚úÖ Data disks: ReadOnly caching for optimal read performance
- ‚úÖ Transaction log disks: None caching for optimal write performance  
- ‚ùå Never use ReadWrite caching for SQL Server data or log disks
- ‚úÖ Cache hit ratio determines the actual performance benefit
- ‚úÖ This configuration provides the best **balance of performance and integrity**

**Reference Links**:
- [SQL Server on Azure VMs - Storage Performance Best Practices](https://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-storage?view=azuresql#data-file-caching-policies)
- [Azure Managed Disks - Host Caching](https://learn.microsoft.com/en-us/azure/virtual-machines/premium-storage-performance#disk-caching)
- [SQL Server on Azure VMs - Performance Guidelines](https://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-checklist?view=azuresql)

**Domain**: Design data storage solutions

---

### Question 6: Purchase Model for License Mobility Customer (Contoso, Ltd.)

**Scenario**: You manage a database environment for a Microsoft Volume Licensing customer named Contoso, Ltd. Contoso uses License Mobility through Software Assurance.

You need to deploy 50 databases. The solution must meet the following requirements:
- Support automatic scaling
- Minimize Microsoft SQL Server licensing costs

**Question**: Which type of purchase model should you include in the recommendation?

**Options**:
- A) DTU
- B) vCore
- C) Azure reserved virtual machine instances

**Correct Answer**: **B) vCore**

**Explanation**:

**vCore** is correct because the vCore (virtual core) purchase model in Azure SQL Database offers greater flexibility in terms of performance scaling and licensing options, including the ability to use **License Mobility through Software Assurance**. Since Contoso is a Microsoft Volume Licensing customer and participates in Software Assurance, they are eligible for the **Azure Hybrid Benefit**, allowing them to bring their own SQL Server licenses to reduce overall SQL licensing costs.

Additionally, the vCore model supports **automatic scaling** (particularly with the serverless tier) and offers **transparent control** over compute, memory, and I/O ‚Äî making it ideal for deploying and managing a large number of databases efficiently.

**Key Benefits of vCore for This Scenario**:
- ‚úÖ Supports Azure Hybrid Benefit (BYOL)
- ‚úÖ License Mobility through Software Assurance compatible
- ‚úÖ Automatic scaling via serverless compute tier
- ‚úÖ Transparent resource control (CPU, memory, I/O)
- ‚úÖ Up to 55% savings with Azure Hybrid Benefit
- ‚úÖ Up to 80% savings with Hybrid Benefit + Reserved Capacity

**Why Other Options Are Incorrect**:

**DTU** is incorrect because the DTU (Database Transaction Unit) model is a bundled compute model with less flexibility. It **does not support Azure Hybrid Benefit or License Mobility through Software Assurance**, and it lacks detailed visibility and control over resource consumption. This leads to higher licensing costs for customers eligible for bring-your-own-license models. For a customer like Contoso with existing SQL Server licenses, the DTU model would result in paying for SQL licensing twice ‚Äî once for their existing licenses and again through the bundled DTU pricing.

**Azure reserved virtual machine instances** is incorrect because while they help reduce costs for SQL Server on Azure VMs, they apply to **IaaS-based deployments, not PaaS-based Azure SQL Databases**. Also, managing 50 databases on VMs would significantly increase operational overhead (patching, backups, high availability configuration, etc.) and not support automatic scaling as efficiently as the PaaS model under vCore. The requirement to minimize SQL Server licensing costs and support automatic scaling points clearly to a PaaS solution with vCore.

**Purchase Model Comparison**:

| Feature | vCore | DTU | Azure VMs |
|---------|-------|-----|----------|
| Azure Hybrid Benefit | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes |
| License Mobility | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes |
| Automatic Scaling | ‚úÖ Serverless | ‚ùå Manual | ‚ùå Manual |
| Resource Transparency | ‚úÖ Full | ‚ùå Bundled | ‚úÖ Full |
| Operational Overhead | Low (PaaS) | Low (PaaS) | High (IaaS) |
| Best for BYOL | ‚úÖ Ideal | ‚ùå No | ‚ö†Ô∏è Complex |

**Reference Links**:
- [vCore-based Purchasing Model](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-sql-database-vcore?view=azuresql)
- [Azure SQL Database Purchasing Models](https://learn.microsoft.com/en-us/azure/azure-sql/database/purchasing-models?view=azuresql)
- [Azure SQL Database Reserved Capacity](https://learn.microsoft.com/en-us/azure/azure-sql/database/reserved-capacity-overview)

**Domain**: Design data storage solutions

---

### Question 7: Data Warehouse Selection for Reporting Solution

**Scenario**: You are designing a data storage solution to support reporting. The solution will ingest high volumes of data in JSON format by using Azure Event Hubs. As the data arrives, Event Hubs will write the data to storage.

The solution must meet the following requirements:
- Organize data in directories by date and time
- Allow stored data to be queried directly, transformed into summarized tables, and then stored in a data warehouse
- Ensure that the data warehouse can store **50 TB of relational data** and support **200-300 concurrent read operations**

**Question**: Which service should you recommend for the data store for the data warehouse?

**Options**:
- A) Azure Cosmos DB Cassandra API
- B) Azure Cosmos DB SQL API
- C) Azure SQL Database Hyperscale
- D) Azure Synapse Analytics dedicated SQL pools

**Correct Answer**: **C) Azure SQL Database Hyperscale**

**Explanation**:

**Azure SQL Database Hyperscale** is correct because it is specifically designed to handle large relational datasets, supporting up to **100 TB of storage**, and offers independent compute and storage scaling, which provides flexibility and cost efficiency. The Hyperscale tier delivers high performance and fast backups, making it suitable for enterprise-grade data workloads. The scenario states that the data warehouse must support 50 TB of relational data and between 200‚Äì300 concurrent read operations, which falls well within the performance and scalability limits of Hyperscale.

**Why Other Options Are Incorrect**:

**Azure Cosmos DB Cassandra API** is incorrect because it is intended for NoSQL column-family workloads and not designed for storing or querying large volumes of relational, structured data. It also does not support analytical queries efficiently and is not cost-effective for 50 TB data storage.

**Azure Cosmos DB SQL API** is incorrect because although it supports JSON-based document storage with flexible schema, it is not a relational database and is unsuitable for warehouse-scale storage or complex SQL-based analytics at the scale described.

**Azure Synapse Analytics dedicated SQL pools** is incorrect in this context because while it is designed for large-scale analytical processing, it is more suitable when working with pre-aggregated or summarized data from a data lake rather than being used as a primary data warehouse for high-volume relational storage with frequent concurrent read access. In this scenario, where relational consistency, transactional support, and high concurrent access are required, Hyperscale is more appropriate.

**Reference Links**:
- [Azure SQL Database Hyperscale](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale?view=azuresql)
- [Azure SQL Managed Instance Resource Limits](https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/resource-limits?view=azuresql)
- [Azure Cosmos DB Introduction](https://learn.microsoft.com/en-us/azure/cosmos-db/introduction)
- [Azure Synapse Analytics Compute Management](https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-manage-compute-overview)

**Domain**: Design data storage solutions

---

## Key Insights for Exams

### Critical Points

1. **Serverless = Auto-scaling + Per-second billing**
   > Only Single Database supports true per-second billing with auto-scaling via Serverless compute tier

2. **Elastic Pool ‚â† Auto-scaling per database**
   > Elastic pools scale at pool level, not individual database level. Resources are shared.

2a. **Elastic Pool + Reserved Capacity = Cost Optimization**
   > Elastic pools support reserved capacity through vCore model, providing up to 80% savings for predictable workloads. Ideal for multiple databases with varying usage patterns.

2b. **Serverless ‚â† Reserved Capacity**
   > Serverless compute tier does NOT support reserved capacity. It's designed for intermittent workloads with auto-pause and per-second billing.

2c. **SQL Server VM Disk Caching**
   > Data disk = ReadOnly caching (optimizes reads) | Transaction log disk = None caching (optimizes writes) | Never use ReadWrite for SQL disks (data corruption risk)

3. **Managed Instance = Near 100% SQL Server compatibility**
   > Choose for lift-and-shift migrations requiring instance-scoped features (SQL Agent, Service Broker)

4. **Business Critical = Local SSD + Read Replica**
   > Business Critical uses local SSD for low latency and includes one free read replica

5. **Hyperscale = Large databases + Fast scaling**
   > Use Hyperscale for databases >4 TB or when rapid scaling is required

6. **Azure Hybrid Benefit = Up to 71% savings**
   > Bring existing SQL Server licenses for significant cost reduction

7. **Zone Redundancy = Higher availability**
   > Zone redundant increases SLA to 99.995% (vs 99.99%)

8. **Single Database vs Elastic Pool**
   > Single DB = dedicated resources | Elastic Pool = shared resources across multiple DBs

9. **Managed Instance for High Resiliency Requirements**
   > When requirements include availability across multiple availability zone failures, minimal I/O latency, and minimal administrative effort, Azure SQL Managed Instance is the correct choice. It supports zone-redundant configuration, automatic failover, geo-replication, and uses local SSD storage (Business Critical tier) for optimal performance while being fully managed.

10. **Auditing Storage Account = Same Region as SQL Server**
   > Azure SQL Database auditing requires the storage account to be in the same region as the SQL server. Cross-region storage is not supported for audit logs. Auditing is supported across all service tiers (Basic, Standard, Premium).

11. **Zero Data Loss Failover = Premium (DTU) or Business Critical (vCore)**
   > Only Premium (DTU) and Business Critical (vCore) tiers provide zero data loss (RPO = 0) during failover. They use Always On availability groups with synchronous replication. For cost optimization with zero data loss and zone redundancy requirements, Premium (DTU) is the most cost-effective option.

12. **Zone Redundancy for High Availability**
   > Basic and Standard (DTU) tiers do NOT support zone redundancy. For zone outage protection, use Premium (DTU), General Purpose (vCore), Business Critical (vCore), or Hyperscale. However, only Premium and Business Critical guarantee zero data loss during failover.

13. **Hyperscale for Large-Scale Relational Data Warehouses**
   > When you need a data warehouse that stores 50+ TB of relational data with 200-300+ concurrent read operations, Azure SQL Database Hyperscale is ideal. It supports up to 100 TB, offers independent compute/storage scaling, and is better suited than Synapse dedicated SQL pools when relational consistency and high concurrent access are required.

14. **vCore Model for License Mobility and Azure Hybrid Benefit**
   > For Microsoft Volume Licensing customers with License Mobility through Software Assurance, the vCore purchasing model is required to leverage Azure Hybrid Benefit. DTU model does NOT support Azure Hybrid Benefit or License Mobility. vCore also supports automatic scaling via serverless tier and provides transparent resource control. Savings can reach up to 80% when combining Azure Hybrid Benefit with reserved capacity.

## Quick Reference Cheat Sheet

### When Requirements Say...

| Requirement | Answer |
|-------------|---------|
| "Auto-scales based on workload" | **Serverless** compute tier |
| "Per-second billing" | **Serverless** compute tier |
| "Multiple databases, cost-effective" | **Elastic Pool** |
| "Multiple databases with varying usage patterns" | **Elastic Pool** |
| "Reserved capacity + multiple databases" | **Elastic Pool (vCore)** |
| "Dynamic scaling + multiple databases" | **Elastic Pool** |
| "SQL Agent, Service Broker" | **Managed Instance** or **SQL VM** |
| "Lift-and-shift from SQL Server" | **Managed Instance** |
| "SQL Server VM data disk caching" | **ReadOnly caching** |
| "SQL Server VM transaction log caching" | **None caching** |
| "Best performance + data integrity for SQL VM" | **Data: ReadOnly, Log: None** |
| "Full OS control" | **SQL Server on Azure VMs** |
| "Mission-critical, low latency" | **Business Critical** tier |
| "Database > 4 TB" | **Hyperscale** tier |
| "Development/test environment" | **Serverless General Purpose** |
| "Modern cloud application" | **Single Database** |
| "Availability if two zones fail" | **Managed Instance** with zone redundancy |
| "Minimal I/O latency + minimal admin" | **Managed Instance Business Critical** |
| "High resiliency + enterprise features" | **Managed Instance** with geo-replication |
| "Store audit logs to storage account" | Storage account must be in **same region** as SQL server |
| "Zero data loss + zone redundancy + minimize cost" | **Premium (DTU)** tier |
| "No data loss during failover" | **Premium (DTU)** or **Business Critical (vCore)** |
| "Zone outage protection" | **Premium**, **General Purpose**, **Business Critical**, or **Hyperscale** (NOT Basic/Standard) |
| "RPO = 0 (zero data loss)" | **Premium (DTU)** or **Business Critical (vCore)** only |
| "50+ TB relational data warehouse" | **Hyperscale** tier |
| "200-300 concurrent read operations" | **Hyperscale** tier |
| "Data warehouse + relational consistency" | **Hyperscale** (not Synapse dedicated pools) |
| "License Mobility through Software Assurance" | **vCore** model (supports Azure Hybrid Benefit) |
| "Minimize SQL licensing costs + BYOL" | **vCore** model with Azure Hybrid Benefit |
| "Volume Licensing customer" | **vCore** model (DTU doesn't support Hybrid Benefit) |

## References

### Microsoft Documentation

- [Azure SQL Database Overview](https://learn.microsoft.com/azure/azure-sql/database/sql-database-paas-overview)
- [Serverless Compute Tier](https://learn.microsoft.com/azure/azure-sql/database/serverless-tier-overview)
- [Azure SQL Managed Instance](https://learn.microsoft.com/azure/azure-sql/managed-instance/sql-managed-instance-paas-overview)
- [SQL Server on Azure VMs](https://learn.microsoft.com/azure/azure-sql/virtual-machines/windows/sql-server-on-azure-vm-iaas-what-is-overview)
- [vCore Model](https://learn.microsoft.com/azure/azure-sql/database/service-tiers-vcore)
- [DTU Model](https://learn.microsoft.com/azure/azure-sql/database/service-tiers-dtu)
- [Elastic Pools](https://learn.microsoft.com/azure/azure-sql/database/elastic-pool-overview)
- [Service Tiers](https://learn.microsoft.com/azure/azure-sql/database/service-tiers-general-purpose-business-critical)
- [High Availability and Zone Redundancy](https://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla-local-zone-redundancy?view=azuresql&tabs=azure-powershell)
- [Service Tiers - DTU Model](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-dtu?view=azuresql)
- [Hyperscale Service Tier](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale?view=azuresql)
- [Azure Hybrid Benefit](https://learn.microsoft.com/azure/azure-sql/azure-hybrid-benefit)
- [Azure SQL Database Auditing](https://learn.microsoft.com/azure/azure-sql/database/auditing-overview)

### Pricing Calculators

- [Azure Pricing Calculator](https://azure.microsoft.com/pricing/calculator/)
- [Azure SQL Database Pricing](https://azure.microsoft.com/pricing/details/azure-sql-database/)
- [Azure SQL Managed Instance Pricing](https://azure.microsoft.com/pricing/details/azure-sql-managed-instance/)

---

**Last Updated**: December 2025  
**Document Version**: 1.0
