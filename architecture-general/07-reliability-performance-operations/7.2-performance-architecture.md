   # 7.2 Performance Architecture

Performance architecture focuses on optimizing response times, throughput, resource efficiency, and user experience. This document covers strategies, patterns, and practices for building high-performance distributed systems.

---

## Table of Contents

- [Overview](#overview)
- [Low-Latency Architecture](#low-latency-architecture)
- [Caching Architecture](#caching-architecture)
- [Load Balancing Architecture](#load-balancing-architecture)
- [Edge Optimization](#edge-optimization)
- [Performance Patterns](#performance-patterns)
- [Performance Metrics and Monitoring](#performance-metrics-and-monitoring)
- [Best Practices](#best-practices)
- [Related Topics](#related-topics)

---

## Overview

Performance is a critical quality attribute that directly impacts user experience, operational costs, and system scalability. A well-designed performance architecture addresses:

- **Latency** – Time to respond to requests
- **Throughput** – Number of requests handled per unit time
- **Resource Efficiency** – Optimal use of compute, memory, and network
- **Scalability** – Ability to handle increased load

### Performance Optimization Layers

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     Performance Optimization Stack                       │
├─────────────────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                    User/Client Layer                             │   │
│  │  • Browser caching  • Compression  • CDN  • Lazy loading        │   │
│  └─────────────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                    Network Layer                                 │   │
│  │  • DNS optimization  • Keep-alive  • HTTP/2  • Connection pool  │   │
│  └─────────────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                    Application Layer                             │   │
│  │  • Caching  • Async processing  • Batching  • Algorithm tuning  │   │
│  └─────────────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                    Data Layer                                    │   │
│  │  • Query optimization  • Indexing  • Denormalization  • Sharding│   │
│  └─────────────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │                    Infrastructure Layer                          │   │
│  │  • Resource scaling  • Colocation  • Hardware optimization      │   │
│  └─────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────┘
```

### Key Performance Concepts

| Concept | Definition | Measurement |
|---------|------------|-------------|
| **Latency** | Time from request to response | Milliseconds (p50, p95, p99) |
| **Throughput** | Request processing rate | Requests per second (RPS) |
| **Bandwidth** | Data transfer capacity | Mbps, Gbps |
| **Utilization** | Resource usage percentage | CPU %, Memory %, etc. |
| **Saturation** | Degree of resource overload | Queue depth, wait time |
| **IOPS** | Storage operations rate | Operations per second |

---

## Low-Latency Architecture

Low-latency architecture minimizes response time for time-sensitive applications such as trading systems, real-time gaming, and interactive applications.

### Latency Sources

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Request Latency Breakdown                            │
│                                                                         │
│  Client ──▶ Network ──▶ Server ──▶ Processing ──▶ Data ──▶ Response   │
│    │          │           │            │           │          │        │
│    ▼          ▼           ▼            ▼           ▼          ▼        │
│  DNS       Routing     Connection   Compute      I/O      Serialize   │
│  Lookup    Latency     Handshake    Time        Wait      Response    │
│  (~50ms)   (~10-100ms) (~100ms)     (varies)    (varies)  (~10ms)     │
│                                                                         │
│  Total Latency = Sum of all components                                 │
└────────────────────────────────────────────────────────────────────────┘
```

### Low-Latency Techniques

| Technique | Description | Latency Reduction |
|-----------|-------------|-------------------|
| **In-Memory Computing** | Keep data in RAM instead of disk | 100x-1000x faster access |
| **Connection Pooling** | Reuse connections, avoid handshake overhead | Eliminate 50-200ms per request |
| **Async/Non-Blocking I/O** | Don't wait for I/O operations | Better resource utilization |
| **Colocation** | Place services near data and users | Reduce network round trips |
| **Optimized Serialization** | Use efficient formats (Protobuf, MessagePack, FlatBuffers) | 2-10x faster than JSON |
| **Kernel Bypass** | Direct hardware access (DPDK, RDMA) | Microsecond latency |
| **Pre-computation** | Calculate results ahead of time | Eliminate compute at request time |

### Connection Pooling

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Without Connection Pooling                           │
│                                                                         │
│  Request 1: [Connect]──[Query]──[Close]                                │
│  Request 2:           [Connect]──[Query]──[Close]                      │
│  Request 3:                     [Connect]──[Query]──[Close]            │
│                                                                         │
│  Each request pays connection overhead                                  │
└────────────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────────────┐
│                    With Connection Pooling                              │
│                                                                         │
│                    ┌─────────────────────────────┐                     │
│                    │      Connection Pool        │                     │
│                    │  ┌───┐ ┌───┐ ┌───┐ ┌───┐  │                     │
│                    │  │ C │ │ C │ │ C │ │ C │  │                     │
│                    │  └───┘ └───┘ └───┘ └───┘  │                     │
│                    └─────────────────────────────┘                     │
│                              │                                          │
│  Request 1: [Acquire]──[Query]──[Return]                               │
│  Request 2: [Acquire]──[Query]──[Return]                               │
│  Request 3: [Acquire]──[Query]──[Return]                               │
│                                                                         │
│  Connections reused, minimal overhead                                   │
└────────────────────────────────────────────────────────────────────────┘
```

| Pool Parameter | Description | Typical Value |
|----------------|-------------|---------------|
| **Min Pool Size** | Minimum connections maintained | 5-10 |
| **Max Pool Size** | Maximum connections allowed | 20-100 |
| **Idle Timeout** | Close idle connections after | 300 seconds |
| **Connection Lifetime** | Max age of a connection | 1800 seconds |
| **Acquire Timeout** | Max wait to get connection | 30 seconds |

### Async Processing Patterns

| Pattern | Description | Use Case |
|---------|-------------|----------|
| **Non-Blocking I/O** | Continue processing while waiting for I/O | High-concurrency servers |
| **Event-Driven** | React to events rather than polling | Real-time applications |
| **Reactive Streams** | Backpressure-aware async processing | Data streaming |
| **Async/Await** | Language-level async support | Modern application code |

### Serialization Performance Comparison

| Format | Serialize Speed | Size | Human Readable | Schema |
|--------|-----------------|------|----------------|--------|
| **JSON** | Baseline | Large | Yes | Optional |
| **Protocol Buffers** | 3-10x faster | Small | No | Required |
| **MessagePack** | 2-4x faster | Medium | No | Optional |
| **FlatBuffers** | Zero-copy | Small | No | Required |
| **Avro** | 2-5x faster | Small | No | Required |

---

## Caching Architecture

Caching stores frequently accessed data closer to consumers, reducing latency and backend load.

### Cache Placement Hierarchy

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      Cache Hierarchy                                     │
│                                                                          │
│   Fastest ◀────────────────────────────────────────────────▶ Slowest   │
│   Smallest                                                    Largest   │
│                                                                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐ │
│  │  L1/L2   │  │ In-Proc  │  │   CDN    │  │  Redis/  │  │ Database │ │
│  │   CPU    │  │  Cache   │  │   Edge   │  │ Memcached│  │  Query   │ │
│  │  Cache   │  │          │  │  Cache   │  │  Cache   │  │  Cache   │ │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘  └──────────┘ │
│      ns            μs            ms            ms            ms        │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### Cache Placement Patterns

| Pattern | Location | Latency | Capacity | Use Case |
|---------|----------|---------|----------|----------|
| **Client-Side Cache** | Browser/Mobile App | ~0ms | Small | Static assets, user preferences |
| **CDN Cache** | Edge locations | 5-50ms | Large | Static content, media, APIs |
| **API Gateway Cache** | Gateway layer | 1-5ms | Medium | API responses, rate limiting |
| **Application Cache** | Service memory | <1ms | Small | Hot data, computed results |
| **Distributed Cache** | Redis/Memcached cluster | 1-10ms | Large | Shared data across instances |
| **Database Cache** | DB buffer/query cache | 1-5ms | Medium | Query results |

### Cache Read Strategies

#### Cache-Aside (Lazy Loading)

Application explicitly manages cache reads and writes.

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Cache-Aside Pattern                                  │
│                                                                         │
│  1. Read Request                                                        │
│     App ──▶ Cache: "Get key X"                                         │
│     Cache ──▶ App: "Miss" or "Hit: value"                              │
│                                                                         │
│  2. On Cache Miss                                                       │
│     App ──▶ Database: "Get X"                                          │
│     Database ──▶ App: "value"                                          │
│     App ──▶ Cache: "Set X = value"                                     │
│                                                                         │
│  ┌─────────┐        ┌─────────┐        ┌─────────┐                     │
│  │   App   │───1───▶│  Cache  │        │   DB    │                     │
│  │         │◀──2────│         │        │         │                     │
│  │         │───3────────────────────▶ │         │                     │
│  │         │◀──4─────────────────────│         │                     │
│  │         │───5───▶│         │        │         │                     │
│  └─────────┘        └─────────┘        └─────────┘                     │
│                                                                         │
└────────────────────────────────────────────────────────────────────────┘
```

| Aspect | Details |
|--------|---------|
| **Pros** | Simple, app controls caching logic, cache only what's needed |
| **Cons** | Cache miss penalty, potential stale data, app complexity |
| **Best For** | Read-heavy workloads, flexibility needed |

#### Read-Through Cache

Cache transparently loads data from database on miss.

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Read-Through Pattern                                 │
│                                                                         │
│  ┌─────────┐        ┌─────────┐        ┌─────────┐                     │
│  │   App   │───────▶│  Cache  │───────▶│   DB    │                     │
│  │         │◀───────│ (Loader)│◀───────│         │                     │
│  └─────────┘        └─────────┘        └─────────┘                     │
│                                                                         │
│  App only talks to cache; cache handles DB interaction                 │
│                                                                         │
└────────────────────────────────────────────────────────────────────────┘
```

| Aspect | Details |
|--------|---------|
| **Pros** | Simpler app code, consistent loading logic |
| **Cons** | First request always slow, cache must know data source |
| **Best For** | When cache provider supports it, predictable data access |

### Cache Write Strategies

#### Write-Through

Write to cache and database simultaneously.

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Write-Through Pattern                                │
│                                                                         │
│  ┌─────────┐        ┌─────────┐        ┌─────────┐                     │
│  │   App   │───────▶│  Cache  │───────▶│   DB    │                     │
│  │         │        │  Write  │  Sync  │  Write  │                     │
│  │         │◀───────│    ✓    │◀───────│    ✓    │                     │
│  └─────────┘        └─────────┘        └─────────┘                     │
│                                                                         │
│  Response only after both writes complete                              │
│                                                                         │
└────────────────────────────────────────────────────────────────────────┘
```

| Aspect | Details |
|--------|---------|
| **Pros** | Strong consistency, data always in cache |
| **Cons** | Write latency (wait for both), underutilized cache for write-heavy |
| **Best For** | Read-heavy with consistency requirements |

#### Write-Behind (Write-Back)

Write to cache immediately, asynchronously persist to database.

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Write-Behind Pattern                                 │
│                                                                         │
│  ┌─────────┐        ┌─────────┐        ┌─────────┐                     │
│  │   App   │───────▶│  Cache  │ ─ ─ ─ ▶│   DB    │                     │
│  │         │◀───────│  Write  │ Async  │  Write  │                     │
│  └─────────┘    ✓   └─────────┘        └─────────┘                     │
│                          │                  ▲                           │
│                          │    Background    │                           │
│                          └──────────────────┘                           │
│                                                                         │
│  Fast response, eventual consistency                                    │
│                                                                         │
└────────────────────────────────────────────────────────────────────────┘
```

| Aspect | Details |
|--------|---------|
| **Pros** | Low write latency, batch writes possible |
| **Cons** | Data loss risk if cache fails, eventual consistency |
| **Best For** | Write-heavy workloads, acceptable eventual consistency |

#### Write-Around

Write directly to database, cache populated on read.

| Aspect | Details |
|--------|---------|
| **Pros** | Cache not polluted by write-once data |
| **Cons** | Cache miss on first read after write |
| **Best For** | Write-once, read-rarely data |

### Cache Invalidation Strategies

| Strategy | Description | Consistency | Complexity |
|----------|-------------|-------------|------------|
| **TTL (Time-To-Live)** | Auto-expire after duration | Eventually consistent | Low |
| **Event-Based** | Invalidate on data change events | Near real-time | Medium |
| **Version-Based** | Include version in cache key | On-demand refresh | Medium |
| **Manual Purge** | Explicit invalidation API | Immediate | High |
| **Cache Tags** | Group related entries, bulk invalidate | Flexible | Medium |

### Cache Eviction Policies

| Policy | Description | Use Case |
|--------|-------------|----------|
| **LRU (Least Recently Used)** | Evict oldest accessed item | General purpose |
| **LFU (Least Frequently Used)** | Evict least accessed item | Hot data preservation |
| **FIFO (First In First Out)** | Evict oldest added item | Time-sensitive data |
| **Random** | Evict random item | Simple, unpredictable workloads |
| **TTL-Based** | Evict expired items first | Time-bound data |

### Caching Best Practices

1. **Cache the right data** – High read frequency, low change rate, expensive to compute
2. **Set appropriate TTLs** – Balance freshness vs. hit rate
3. **Handle cache failures gracefully** – Fallback to source
4. **Monitor hit rates** – Target 80%+ hit rate
5. **Avoid cache stampede** – Use locks or probabilistic early expiration
6. **Size cache appropriately** – Monitor memory usage and eviction rates

---

## Load Balancing Architecture

Load balancing distributes traffic across multiple instances to improve availability, scalability, and performance.

### Load Balancing Layers

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    Load Balancing Architecture                          │
│                                                                         │
│                         ┌───────────────────┐                          │
│                         │   DNS Load        │                          │
│                         │   Balancing       │  Global traffic routing  │
│                         └─────────┬─────────┘                          │
│                                   │                                     │
│              ┌────────────────────┼────────────────────┐               │
│              ▼                    ▼                    ▼               │
│    ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐      │
│    │  Region A       │  │  Region B       │  │  Region C       │      │
│    │  ┌───────────┐  │  │  ┌───────────┐  │  │  ┌───────────┐  │      │
│    │  │ L7 Load   │  │  │  │ L7 Load   │  │  │  │ L7 Load   │  │      │
│    │  │ Balancer  │  │  │  │ Balancer  │  │  │  │ Balancer  │  │      │
│    │  └─────┬─────┘  │  │  └─────┬─────┘  │  │  └─────┬─────┘  │      │
│    │        │        │  │        │        │  │        │        │      │
│    │  ┌─────┴─────┐  │  │  ┌─────┴─────┐  │  │  ┌─────┴─────┐  │      │
│    │  │ L4 Load   │  │  │  │ L4 Load   │  │  │  │ L4 Load   │  │      │
│    │  │ Balancer  │  │  │  │ Balancer  │  │  │  │ Balancer  │  │      │
│    │  └─────┬─────┘  │  │  └─────┬─────┘  │  │  └─────┬─────┘  │      │
│    │    ┌───┼───┐    │  │    ┌───┼───┐    │  │    ┌───┼───┐    │      │
│    │    ▼   ▼   ▼    │  │    ▼   ▼   ▼    │  │    ▼   ▼   ▼    │      │
│    │   [S] [S] [S]   │  │   [S] [S] [S]   │  │   [S] [S] [S]   │      │
│    └─────────────────┘  └─────────────────┘  └─────────────────┘      │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Load Balancer Types

| Type | OSI Layer | Description | Features |
|------|-----------|-------------|----------|
| **L4 (Transport)** | Layer 4 | Routes based on IP/port | Fast, connection-based, TCP/UDP |
| **L7 (Application)** | Layer 7 | Routes based on content | HTTP routing, SSL termination, URL/header-based |
| **DNS** | DNS | Returns different IPs | Geographic routing, simple failover |
| **Global** | Cross-region | Multi-region routing | Latency-based, failover, geographic |

### Load Balancing Algorithms

| Algorithm | Description | Best For |
|-----------|-------------|----------|
| **Round Robin** | Sequential rotation through servers | Equal capacity, stateless |
| **Weighted Round Robin** | Proportional distribution by weight | Different server capacities |
| **Least Connections** | Route to server with fewest active connections | Long-lived connections |
| **Least Response Time** | Route to fastest responding server | Performance optimization |
| **IP Hash** | Consistent routing based on client IP | Session persistence |
| **URL Hash** | Route based on request URL | Cache optimization |
| **Random** | Random server selection | Simple, stateless workloads |
| **Resource-Based** | Route based on server health/capacity | Dynamic workloads |

### Algorithm Comparison

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Round Robin                                          │
│                                                                         │
│  Requests:  R1 ─▶ S1    R2 ─▶ S2    R3 ─▶ S3    R4 ─▶ S1              │
│                                                                         │
│  Simple, doesn't account for server load or capacity                    │
└────────────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────────────┐
│                    Least Connections                                    │
│                                                                         │
│  Server Status:  S1 (5 conn)   S2 (2 conn)   S3 (8 conn)              │
│  New Request ──▶ S2 (lowest connections)                               │
│                                                                         │
│  Better for varying request durations                                   │
└────────────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────────────┐
│                    Weighted Round Robin                                 │
│                                                                         │
│  Server Weights:  S1 (weight=3)  S2 (weight=1)  S3 (weight=2)         │
│  Distribution:    S1, S1, S1, S2, S3, S3, S1, S1, S1, ...             │
│                                                                         │
│  Good when servers have different capacities                            │
└────────────────────────────────────────────────────────────────────────┘
```

### Session Persistence (Sticky Sessions)

| Method | Description | Pros | Cons |
|--------|-------------|------|------|
| **Cookie-Based** | LB sets session cookie | Works through NAT | Requires cookie support |
| **IP Hash** | Hash client IP to server | No cookies needed | NAT/proxy issues |
| **URL Parameter** | Session ID in URL | Universal support | URL pollution |
| **Application** | Distributed session store | True stateless | Additional infrastructure |

### Health Checks

| Check Type | Description | Interval |
|------------|-------------|----------|
| **TCP** | Port connectivity | 5-10s |
| **HTTP** | Endpoint response code | 10-30s |
| **HTTPS** | Secure endpoint check | 10-30s |
| **Custom Script** | Application-specific logic | Varies |

---

## Edge Optimization

Edge optimization processes data and serves content closer to users, reducing latency and improving user experience.

### Edge Architecture Components

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    Edge Architecture                                     │
│                                                                          │
│  Users                    Edge                        Origin             │
│  ─────                    ────                        ──────             │
│                                                                          │
│  ┌───────┐           ┌─────────────┐             ┌─────────────┐        │
│  │ User  │──────────▶│   CDN PoP   │────────────▶│   Origin    │        │
│  │  NA   │           │  (Edge)     │  Cache Miss │   Server    │        │
│  └───────┘           │             │             │             │        │
│                      │ • Cache     │             │             │        │
│  ┌───────┐           │ • Compute   │             │             │        │
│  │ User  │──────────▶│ • Security  │             │             │        │
│  │  EU   │           │ • Optimize  │             │             │        │
│  └───────┘           └─────────────┘             └─────────────┘        │
│                            │                                             │
│  ┌───────┐           ┌─────────────┐                                    │
│  │ User  │──────────▶│   CDN PoP   │  Cache Hit ─▶ Response            │
│  │ APAC  │           │   (Local)   │                                    │
│  └───────┘           └─────────────┘                                    │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### Content Delivery Network (CDN)

| Feature | Description |
|---------|-------------|
| **Static Caching** | Cache images, CSS, JS, fonts at edge |
| **Dynamic Caching** | Cache API responses with appropriate TTLs |
| **SSL/TLS Termination** | Handle encryption at edge |
| **Compression** | Gzip/Brotli compression at edge |
| **Image Optimization** | Resize, format conversion (WebP, AVIF) |
| **DDoS Protection** | Absorb attack traffic at edge |

### CDN Caching Strategies

| Content Type | Cache Duration | Cache-Control Header |
|--------------|----------------|----------------------|
| Static assets (versioned) | 1 year | `public, max-age=31536000, immutable` |
| Static assets (unversioned) | 1 day | `public, max-age=86400` |
| HTML pages | Short/no cache | `no-cache` or `max-age=60` |
| API responses | Varies | `private, max-age=60` |
| User-specific content | No cache | `private, no-store` |

### Edge Computing

Run compute workloads at edge locations, closer to users.

| Use Case | Description | Example |
|----------|-------------|---------|
| **Request Routing** | Route based on user location, device | A/B testing, personalization |
| **Authentication** | Validate tokens at edge | JWT verification |
| **Data Transformation** | Modify responses on the fly | Image resizing, format conversion |
| **Aggregation** | Combine multiple API calls | GraphQL at edge |
| **Security** | Block threats at edge | Bot detection, WAF |

### Edge Functions / Serverless at Edge

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Edge Function Flow                                   │
│                                                                         │
│   ┌──────────┐     ┌──────────────┐     ┌──────────────┐              │
│   │  Client  │────▶│ Edge Function │────▶│    Origin    │              │
│   │  Request │     │   (Process)   │     │   (if needed)│              │
│   └──────────┘     └──────────────┘     └──────────────┘              │
│                           │                                             │
│                    Can return response                                  │
│                    without hitting origin                               │
│                                                                         │
│   Use Cases:                                                            │
│   • A/B Testing            • Geolocation redirects                     │
│   • Authentication         • Header manipulation                        │
│   • URL rewriting          • Response transformation                    │
│                                                                         │
└────────────────────────────────────────────────────────────────────────┘
```

### Edge Providers Comparison

| Provider | Edge Functions | CDN | Key Features |
|----------|---------------|-----|--------------|
| **Cloudflare Workers** | Yes | Yes | V8 isolates, global network |
| **AWS CloudFront + Lambda@Edge** | Yes | Yes | AWS integration, regional edge |
| **Azure Front Door + Functions** | Yes | Yes | Azure integration, WAF |
| **Fastly Compute@Edge** | Yes | Yes | WebAssembly, real-time logs |
| **Vercel Edge** | Yes | Yes | Next.js optimized |
| **Akamai EdgeWorkers** | Yes | Yes | Enterprise, largest network |

---

## Performance Patterns

### Batching Pattern

Combine multiple operations into a single batch to reduce overhead.

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Without Batching                                     │
│                                                                         │
│   Client ──req1──▶ Server     (overhead)                               │
│   Client ──req2──▶ Server     (overhead)                               │
│   Client ──req3──▶ Server     (overhead)                               │
│                                                                         │
│   3 requests × network overhead = High latency                          │
└────────────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────────────┐
│                    With Batching                                        │
│                                                                         │
│   Client ──[req1, req2, req3]──▶ Server                                │
│   Client ◀──[res1, res2, res3]── Server                                │
│                                                                         │
│   1 request × network overhead = Lower latency                          │
└────────────────────────────────────────────────────────────────────────┘
```

| Consideration | Guidance |
|---------------|----------|
| **Batch Size** | Balance latency vs. throughput (typically 10-100 items) |
| **Timeout** | Set max wait time for batch to fill |
| **Partial Failure** | Handle individual item failures gracefully |
| **Ordering** | Preserve order if required |

### Throttling Pattern

Control resource consumption to protect system stability.

| Strategy | Description | Use Case |
|----------|-------------|----------|
| **Request Throttling** | Limit requests per time window | API protection |
| **Bandwidth Throttling** | Limit data transfer rate | Network fairness |
| **Resource Throttling** | Limit CPU/memory per tenant | Multi-tenant systems |
| **Priority Throttling** | Different limits by tier | Tiered service levels |

### Async Request-Reply Pattern

Handle long-running operations without blocking.

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Async Request-Reply Pattern                          │
│                                                                         │
│   Client              API Gateway           Worker                      │
│     │                     │                   │                         │
│     │──POST /jobs────────▶│                   │                         │
│     │◀──202 Accepted──────│                   │                         │
│     │   Location: /jobs/123                   │                         │
│     │                     │──Queue Job───────▶│                         │
│     │                     │                   │──Processing...          │
│     │──GET /jobs/123─────▶│                   │                         │
│     │◀──200 {status:      │                   │                         │
│     │      "processing"}──│                   │                         │
│     │                     │                   │                         │
│     │                     │◀──Complete────────│                         │
│     │──GET /jobs/123─────▶│                   │                         │
│     │◀──200 {status:      │                   │                         │
│     │      "complete",    │                   │                         │
│     │      result: ...}───│                   │                         │
│                                                                         │
│   Alternative: Use webhooks for completion notification                 │
│                                                                         │
└────────────────────────────────────────────────────────────────────────┘
```

### Materialized View Pattern

Pre-compute and store query results for fast retrieval.

```
┌────────────────────────────────────────────────────────────────────────┐
│                    Materialized View Pattern                            │
│                                                                         │
│   Source Tables                    Materialized View                    │
│   ┌─────────────┐                  ┌─────────────────────────┐         │
│   │   Orders    │──┐               │   Sales Dashboard View   │         │
│   └─────────────┘  │               │   ┌───────────────────┐ │         │
│   ┌─────────────┐  │  Compute &    │   │ Region │ Revenue  │ │         │
│   │  Products   │──┼──Store───────▶│   │ NA     │ $1.2M    │ │         │
│   └─────────────┘  │               │   │ EU     │ $800K    │ │         │
│   ┌─────────────┐  │               │   │ APAC   │ $600K    │ │         │
│   │  Customers  │──┘               │   └───────────────────┘ │         │
│   └─────────────┘                  └─────────────────────────┘         │
│                                                                         │
│   Complex joins/aggregations done once, reads are fast                  │
│                                                                         │
└────────────────────────────────────────────────────────────────────────┘
```

| Refresh Strategy | Description | Freshness |
|------------------|-------------|-----------|
| **Scheduled** | Rebuild at intervals | Minutes to hours |
| **Incremental** | Update only changes | Near real-time |
| **Event-Driven** | Trigger on data changes | Real-time |
| **On-Demand** | Refresh when queried (if stale) | Configurable |

### Compression Pattern

Reduce data size to improve transfer speed.

| Algorithm | Compression Ratio | Speed | Use Case |
|-----------|-------------------|-------|----------|
| **Gzip** | Good | Fast | HTTP responses (widely supported) |
| **Brotli** | Better | Slower | HTTP responses (modern browsers) |
| **LZ4** | Lower | Very fast | Real-time data, logs |
| **Zstd** | Better | Fast | General purpose, configurable |
| **Snappy** | Lower | Very fast | Big data, streaming |

### Data Pagination Patterns

| Pattern | Description | Pros | Cons |
|---------|-------------|------|------|
| **Offset/Limit** | Skip N items, return M | Simple, random access | Slow for large offsets |
| **Cursor/Keyset** | Use last item as reference | Consistent, fast | No random access |
| **Page Token** | Opaque token for next page | Flexible, stable | Server must track state |

---

## Performance Metrics and Monitoring

### Key Performance Metrics

| Category | Metric | Description | Target |
|----------|--------|-------------|--------|
| **Latency** | p50 | Median response time | < 100ms |
| **Latency** | p95 | 95th percentile | < 500ms |
| **Latency** | p99 | 99th percentile | < 1000ms |
| **Throughput** | RPS | Requests per second | Based on load |
| **Errors** | Error Rate | Failed requests percentage | < 0.1% |
| **Saturation** | CPU Usage | Processor utilization | < 70% |
| **Saturation** | Memory Usage | RAM utilization | < 80% |
| **Saturation** | Queue Depth | Pending requests | Near 0 |

### The USE Method

| Metric | Description | What It Tells You |
|--------|-------------|-------------------|
| **Utilization** | % time resource is busy | Capacity usage |
| **Saturation** | Work waiting in queue | Overload indication |
| **Errors** | Error events count | Failure rate |

### The RED Method (for Services)

| Metric | Description | What It Tells You |
|--------|-------------|-------------------|
| **Rate** | Requests per second | Traffic volume |
| **Errors** | Failed requests per second | Reliability |
| **Duration** | Request latency distribution | Performance |

### Performance Testing Types

| Type | Purpose | When |
|------|---------|------|
| **Load Testing** | Behavior under expected load | Before release |
| **Stress Testing** | Breaking point identification | Capacity planning |
| **Spike Testing** | Response to sudden load increase | Event preparation |
| **Soak Testing** | Stability over extended period | Memory leak detection |
| **Scalability Testing** | Scaling behavior | Architecture validation |

---

## Best Practices

### Performance Design Principles

1. **Measure first** – Profile before optimizing; don't guess
2. **Optimize the critical path** – Focus on the most impactful areas
3. **Cache aggressively** – But invalidate correctly
4. **Minimize network calls** – Batch, compress, colocate
5. **Async where possible** – Don't block on I/O
6. **Design for horizontal scaling** – Stateless, distributed

### Performance Checklist

#### Application Level
- [ ] Profile and identify bottlenecks
- [ ] Implement caching at appropriate layers
- [ ] Use connection pooling
- [ ] Optimize database queries (indexes, EXPLAIN)
- [ ] Implement async processing for long operations
- [ ] Use efficient serialization formats

#### Network Level
- [ ] Enable HTTP/2 or HTTP/3
- [ ] Configure keep-alive connections
- [ ] Enable compression (Gzip/Brotli)
- [ ] Use CDN for static content
- [ ] Minimize redirects

#### Infrastructure Level
- [ ] Right-size compute resources
- [ ] Configure auto-scaling
- [ ] Use appropriate storage tiers
- [ ] Place resources in optimal regions
- [ ] Implement load balancing

### Anti-Patterns to Avoid

| Anti-Pattern | Problem | Solution |
|--------------|---------|----------|
| **Chatty Services** | Too many small network calls | Batch requests, aggregate APIs |
| **N+1 Queries** | Query per item in collection | Use JOINs, batch loading |
| **Unbounded Queries** | Return all records | Implement pagination |
| **Synchronous Everything** | Blocking on I/O | Async processing, queues |
| **Cache Everything** | Memory exhaustion, stale data | Cache strategically with TTLs |
| **Premature Optimization** | Wasted effort on non-bottlenecks | Profile first, optimize second |

---

## Related Topics

- [Reliability Performance Operations Patterns](./reliability-performance-operations-patterns.md) - Comprehensive patterns reference
- [7.1 Reliability Architecture](./7.1-reliability-architecture.md) - Reliability patterns
- [7.3 Observability Architecture](./7.3-observability-architecture/) - Monitoring and observability
- [Azure Load Balancing](../../architecture-azure/networking/load-balancing/) - Azure load balancing services
- [Azure Redis Cache](../../architecture-azure/data/redis/) - Azure caching services

---

## References

- High Performance Browser Networking - Ilya Grigorik
- Designing Data-Intensive Applications - Martin Kleppmann
- Web Performance in Action - Jeremy Wagner
- Google Web Vitals Documentation
- CDN Best Practices - Cloudflare, Akamai, AWS
