# The RED Method

## Table of Contents

- [Overview](#overview)
- [What is the RED Method?](#what-is-the-red-method)
- [The Three Metrics](#the-three-metrics)
  - [Rate](#rate)
  - [Errors](#errors)
  - [Duration](#duration)
- [When to Use RED](#when-to-use-red)
- [Implementation Guide](#implementation-guide)
- [Dashboard Design](#dashboard-design)
- [Alerting Strategies](#alerting-strategies)
- [RED by Service Type](#red-by-service-type)
- [RED vs. Golden Signals](#red-vs-golden-signals)
- [Common Pitfalls](#common-pitfalls)
- [Tools and Examples](#tools-and-examples)

---

## Overview

The **RED Method** is a monitoring methodology specifically designed for **request-driven services** (microservices, APIs, web applications). It was created by Tom Wilkie at Weave Works and focuses on three key metrics that directly reflect user experience.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      THE RED METHOD                              â”‚
â”‚                                                                  â”‚
â”‚              For every service, monitor:                         â”‚
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚     RATE     â”‚  â”‚    ERRORS    â”‚  â”‚   DURATION   â”‚        â”‚
â”‚    â”‚              â”‚  â”‚              â”‚  â”‚              â”‚        â”‚
â”‚    â”‚  Requests    â”‚  â”‚   Failed     â”‚  â”‚   Response   â”‚        â”‚
â”‚    â”‚  per second  â”‚  â”‚   requests   â”‚  â”‚     time     â”‚        â”‚
â”‚    â”‚              â”‚  â”‚              â”‚  â”‚              â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â”‚    "How busy?"       "How broken?"      "How slow?"             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What is the RED Method?

### Origin

Created by **Tom Wilkie** (Weaveworks/Grafana Labs) as a simplified monitoring approach for microservices architectures. It distills monitoring to the three most essential metrics for request-driven services.

### Philosophy

> "For every service, monitor request **Rate**, request **Errors**, and request **Duration**"

The RED Method prioritizes **simplicity** and **consistency**â€”by using the same three metrics across all services, teams can quickly understand any service's health.

### Key Principles

1. **Simplicity**: Three metrics cover essential service health
2. **Consistency**: Same metrics across all services
3. **User-centric**: Metrics reflect what users experience
4. **Actionable**: Deviations directly indicate problems

---

## The Three Metrics

### Rate

**Definition**: The number of requests your service is handling per second.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          RATE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  What it measures:    Request throughput                         â”‚
â”‚  Unit:                Requests per second (req/s)                â”‚
â”‚  Dimension by:        Endpoint, method, status, client           â”‚
â”‚                                                                  â”‚
â”‚  Why it matters:                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚  â€¢ Indicates service demand/load                                 â”‚
â”‚  â€¢ Helps with capacity planning                                  â”‚
â”‚  â€¢ Detects traffic anomalies (spikes, drops)                    â”‚
â”‚  â€¢ Correlates with business metrics                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Rate Metrics to Track

| Metric | Description | Use Case |
|--------|-------------|----------|
| Total request rate | All requests/sec | Overall load |
| Rate by endpoint | Requests/sec per API endpoint | Endpoint-specific load |
| Rate by status | Requests/sec by HTTP status | Success vs. failure distribution |
| Rate by client | Requests/sec by caller | Identify heavy users |

#### Rate Calculation

```python
# Prometheus PromQL
rate(http_requests_total[5m])

# By endpoint
sum(rate(http_requests_total[5m])) by (endpoint)

# Success vs. failure
sum(rate(http_requests_total{status=~"2.."}[5m]))  # Success
sum(rate(http_requests_total{status=~"5.."}[5m]))  # Errors
```

#### Rate Patterns to Watch

```
Normal Pattern:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â”‚  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
Rate â”‚ â•±              â•²   Daily peak
     â”‚â•±                â•²
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time
       6am            6pm

Anomaly: Sudden Drop (potential outage)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â”‚  â•­â”€â”€â”€â”€â”€â•®
Rate â”‚ â•±      â”‚
     â”‚â•±       â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€  âš ï¸ Alert!
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time

Anomaly: Sudden Spike (attack or viral content)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â”‚              â•­â”€â”€â”€â”€â”€
Rate â”‚              â”‚      âš ï¸ Alert!
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time
```

---

### Errors

**Definition**: The number of requests that are failing per second.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ERRORS                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  What it measures:    Failed request count/rate                  â”‚
â”‚  Units:               Errors/sec or Error rate (%)               â”‚
â”‚  Dimension by:        Error type, endpoint, error code           â”‚
â”‚                                                                  â”‚
â”‚  Error Categories:                                               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚  â€¢ HTTP 5xx         - Server errors (your fault)                 â”‚
â”‚  â€¢ HTTP 4xx         - Client errors (usually their fault)        â”‚
â”‚  â€¢ Timeouts         - Request exceeded time limit                â”‚
â”‚  â€¢ Business errors  - Application-level failures                 â”‚
â”‚  â€¢ Partial failures - Degraded responses                         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Error Metrics to Track

| Metric | Formula | Interpretation |
|--------|---------|----------------|
| Error count | `sum(errors)` | Absolute failure volume |
| Error rate | `errors / total * 100` | Percentage of failures |
| Error by type | `sum(errors) by (type)` | Root cause distribution |
| Error by endpoint | `sum(errors) by (endpoint)` | Problem hotspots |

#### Error Rate Calculation

```python
# Prometheus PromQL - Error Rate
sum(rate(http_requests_total{status=~"5.."}[5m])) 
/ 
sum(rate(http_requests_total[5m])) 
* 100

# By endpoint
sum(rate(http_requests_total{status=~"5.."}[5m])) by (endpoint)
/
sum(rate(http_requests_total[5m])) by (endpoint)
* 100
```

#### Error Classification Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ERROR CLASSIFICATION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Status Code  â”‚ Category   â”‚ Severity     â”‚ Typical Cause       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 400          â”‚ Client     â”‚ Low          â”‚ Bad request format  â”‚
â”‚ 401          â”‚ Client     â”‚ Low          â”‚ Not authenticated   â”‚
â”‚ 403          â”‚ Client     â”‚ Low          â”‚ Not authorized      â”‚
â”‚ 404          â”‚ Client     â”‚ Low          â”‚ Resource not found  â”‚
â”‚ 429          â”‚ Client     â”‚ Medium       â”‚ Rate limited        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 500          â”‚ Server     â”‚ High         â”‚ Internal error      â”‚
â”‚ 502          â”‚ Server     â”‚ High         â”‚ Bad gateway         â”‚
â”‚ 503          â”‚ Server     â”‚ Critical     â”‚ Service unavailable â”‚
â”‚ 504          â”‚ Server     â”‚ High         â”‚ Gateway timeout     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Note: Focus on 5xx errors - these indicate problems within your control
```

---

### Duration

**Definition**: The distribution of time it takes to handle requests (latency).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DURATION                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  What it measures:    Request response time                      â”‚
â”‚  Unit:                Milliseconds (ms) or seconds (s)           â”‚
â”‚  Track as:            HISTOGRAM (not average!)                   â”‚
â”‚  Key percentiles:     P50, P90, P95, P99, P99.9                 â”‚
â”‚                                                                  â”‚
â”‚  Why histogram over average:                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                     â”‚
â”‚  â€¢ Averages hide outliers                                        â”‚
â”‚  â€¢ Percentiles show distribution                                 â”‚
â”‚  â€¢ P99 reveals worst-case experience                            â”‚
â”‚  â€¢ Better for SLO definition                                     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Duration Percentiles Explained

```
                    Duration Distribution
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Request
Count   â”‚
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆ
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–²           â–²            â–²           â–²
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚           â”‚            â”‚           â”‚
        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚           â”‚            â”‚           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–º Time
                      â”‚           â”‚            â”‚           â”‚
                     P50        P90          P95         P99
                    50ms      150ms        250ms       800ms

        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        50% of users  â”‚
        are here      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                      90% of usersâ”‚
                      are here    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                  95% of users â”‚
                                  are here     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                               99% here    â”‚
                                                          1% worst
                                                          experience
```

#### Duration Metrics to Track

| Percentile | Description | Typical SLO |
|------------|-------------|-------------|
| P50 | Median - typical experience | < 100ms |
| P90 | Most users | < 200ms |
| P95 | Nearly all users | < 500ms |
| P99 | Tail latency | < 1000ms |
| P99.9 | Extreme outliers | < 2000ms |

#### Duration Calculation

```python
# Prometheus PromQL - Percentiles from histogram
histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))  # P50
histogram_quantile(0.90, rate(http_request_duration_seconds_bucket[5m]))  # P90
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))  # P95
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))  # P99

# By endpoint
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
)
```

---

## When to Use RED

### Ideal Use Cases

| Service Type | RED Applicability | Notes |
|--------------|-------------------|-------|
| REST APIs | âœ… Excellent | Primary use case |
| GraphQL APIs | âœ… Excellent | Track by operation |
| gRPC services | âœ… Excellent | Native support |
| Web applications | âœ… Excellent | Include page loads |
| Microservices | âœ… Excellent | Per-service metrics |
| Serverless functions | âœ… Good | Track invocations |

### Less Suitable For

| System Type | Better Alternative | Reason |
|-------------|-------------------|--------|
| Databases | USE Method | Resource-focused |
| Caches | USE Method | Utilization matters more |
| Message queues | Modified RED | Add queue depth |
| Infrastructure | USE Method | CPU, memory, disk focus |

---

## Implementation Guide

### Step 1: Instrument Your Service

```python
# Python with OpenTelemetry
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider

meter = metrics.get_meter("my-service")

# RATE - Counter for request count
request_counter = meter.create_counter(
    name="http_requests_total",
    description="Total HTTP requests",
    unit="requests"
)

# ERRORS - Counter for error count
error_counter = meter.create_counter(
    name="http_errors_total",
    description="Total HTTP errors",
    unit="errors"
)

# DURATION - Histogram for latency
request_duration = meter.create_histogram(
    name="http_request_duration_seconds",
    description="HTTP request duration",
    unit="s"
)

# Usage
def handle_request(request):
    start = time.time()
    status = "success"
    
    try:
        response = process(request)
    except Exception as e:
        status = "error"
        error_counter.add(1, {"endpoint": request.path, "error": type(e).__name__})
        raise
    finally:
        duration = time.time() - start
        request_counter.add(1, {"endpoint": request.path, "status": status})
        request_duration.record(duration, {"endpoint": request.path})
    
    return response
```

### Step 2: Define Labels/Dimensions

```yaml
# Recommended labels for RED metrics
labels:
  # Common labels
  - service: "payment-api"
  - version: "v2.1.0"
  - environment: "production"
  
  # Request-specific labels
  - endpoint: "/api/v1/payments"
  - method: "POST"
  - status_code: "200"
  
  # Error-specific labels (for error counter)
  - error_type: "timeout"
  - error_code: "PAYMENT_FAILED"
```

### Step 3: Configure Histogram Buckets

```python
# Choose buckets appropriate for your service
duration_buckets = [
    0.005,  # 5ms
    0.01,   # 10ms
    0.025,  # 25ms
    0.05,   # 50ms
    0.1,    # 100ms
    0.25,   # 250ms
    0.5,    # 500ms
    1.0,    # 1s
    2.5,    # 2.5s
    5.0,    # 5s
    10.0,   # 10s
]

# For fast services (cache, simple APIs)
fast_buckets = [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]

# For slow services (data processing, reports)
slow_buckets = [0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0]
```

---

## Dashboard Design

### RED Dashboard Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SERVICE: Order API    ENV: Production    VERSION: 2.1.0    [Last 6h â–¼]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   ğŸ“Š RATE          â”‚  â”‚   âŒ ERRORS        â”‚  â”‚   â±ï¸ DURATION      â”‚    â”‚
â”‚  â”‚                    â”‚  â”‚                    â”‚  â”‚                    â”‚    â”‚
â”‚  â”‚   1,234 req/s      â”‚  â”‚   0.12% error     â”‚  â”‚   P50: 45ms       â”‚    â”‚
â”‚  â”‚   â–² +5% vs 1h ago  â”‚  â”‚   rate            â”‚  â”‚   P99: 320ms      â”‚    â”‚
â”‚  â”‚                    â”‚  â”‚   âœ… Healthy      â”‚  â”‚   âœ… Healthy      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                     RATE OVER TIME                                     â”‚ â”‚
â”‚  â”‚  2K â”€â”¤                        â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚ â”‚
â”‚  â”‚      â”‚                   â•­â”€â”€â”€â•¯                                         â”‚ â”‚
â”‚  â”‚  1K â”€â”¤â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”‚ â”‚
â”‚  â”‚      â”‚                                                                  â”‚ â”‚
â”‚  â”‚   0 â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€    â”‚ â”‚
â”‚  â”‚             -6h      -5h      -4h      -3h      -2h      -1h   Now     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚       ERROR RATE OVER TIME      â”‚  â”‚      DURATION PERCENTILES       â”‚ â”‚
â”‚  â”‚  5% â”€â”¤                          â”‚  â”‚  1s â”€â”¤                  â•­â”€â”€â”€â”€   â”‚ â”‚
â”‚  â”‚      â”‚                          â”‚  â”‚      â”‚             â•­â”€â”€â”€â•¯ P99    â”‚ â”‚
â”‚  â”‚  2% â”€â”¤                          â”‚  â”‚500msâ”€â”¤         â•­â”€â”€â•¯             â”‚ â”‚
â”‚  â”‚      â”‚     â•­â•®                   â”‚  â”‚      â”‚    â•­â”€â”€â”€â•¯     P95         â”‚ â”‚
â”‚  â”‚  0% â”€â”¤â”€â”€â”€â”€â”€â•¯â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚100msâ”€â”¤â”€â”€â”€â•¯â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ P50      â”‚ â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    BY ENDPOINT                                         â”‚ â”‚
â”‚  â”‚  Endpoint          Rate       Errors    P50      P99                  â”‚ â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚ â”‚
â”‚  â”‚  /api/orders       800/s      0.1%      35ms     250ms    âœ…          â”‚ â”‚
â”‚  â”‚  /api/payments     300/s      0.3%      80ms     450ms    âœ…          â”‚ â”‚
â”‚  â”‚  /api/inventory    134/s      1.2%      45ms     890ms    âš ï¸          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Alerting Strategies

### Alert Rules

```yaml
groups:
  - name: red_alerts
    rules:
      # RATE: Traffic anomaly detection
      - alert: TrafficSpike
        expr: |
          rate(http_requests_total[5m]) > 
          2 * avg_over_time(rate(http_requests_total[5m])[1h:5m])
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Traffic spike detected - 2x normal"
          
      - alert: TrafficDrop
        expr: |
          rate(http_requests_total[5m]) < 
          0.5 * avg_over_time(rate(http_requests_total[5m])[1h:5m])
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "Traffic dropped below 50% of normal"

      # ERRORS: Error rate thresholds
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total[5m])) by (service)
          > 0.01
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Error rate >1% for {{ $labels.service }}"
          
      - alert: CriticalErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
          / sum(rate(http_requests_total[5m])) by (service)
          > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Error rate >5% for {{ $labels.service }}"

      # DURATION: Latency thresholds
      - alert: HighP99Latency
        expr: |
          histogram_quantile(0.99, 
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "P99 latency >1s for {{ $labels.service }}"
          
      - alert: LatencyDegradation
        expr: |
          histogram_quantile(0.99, 
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 
          3 * histogram_quantile(0.99, 
            sum(rate(http_request_duration_seconds_bucket[1h])) by (le, service)
          )
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "P99 latency 3x higher than 1h average"
```

### Alert Priority Matrix

| Metric | Condition | Severity | Action |
|--------|-----------|----------|--------|
| Rate | Drop >50% | Critical | Immediate investigation |
| Rate | Spike >200% | Warning | Check for attack/anomaly |
| Errors | Rate >1% | Warning | Investigate within 1h |
| Errors | Rate >5% | Critical | Page on-call |
| Duration | P99 >1s | Warning | Investigate |
| Duration | P99 >3x baseline | Critical | Page on-call |

---

## RED by Service Type

### REST API

```yaml
metrics:
  rate:
    - http_requests_total{method, endpoint, status}
  errors:
    - http_requests_total{status=~"5.."}
    - http_requests_total{status=~"4.."}  # separate tracking
  duration:
    - http_request_duration_seconds{method, endpoint}
```

### GraphQL API

```yaml
metrics:
  rate:
    - graphql_operations_total{operation_name, operation_type}
  errors:
    - graphql_errors_total{operation_name, error_type}
  duration:
    - graphql_operation_duration_seconds{operation_name}
```

### gRPC Service

```yaml
metrics:
  rate:
    - grpc_server_handled_total{service, method, code}
  errors:
    - grpc_server_handled_total{code!="OK"}
  duration:
    - grpc_server_handling_seconds{service, method}
```

### Serverless Function

```yaml
metrics:
  rate:
    - function_invocations_total{function_name, trigger_type}
  errors:
    - function_errors_total{function_name, error_type}
  duration:
    - function_duration_seconds{function_name}
```

---

## RED vs. Golden Signals

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RED METHOD vs. GOLDEN SIGNALS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  RED METHOD                    GOLDEN SIGNALS                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•                    â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   Rate   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Traffic    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚       Same concept, different name                               â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Errors  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    Errors    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚       Identical                                                  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Duration â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Latency    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚       Same concept, different name                               â”‚
â”‚                                                                  â”‚
â”‚                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚       NOT IN RED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Saturation  â”‚                 â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚       RED doesn't include saturation                             â”‚
â”‚       (resource-level metric)                                    â”‚
â”‚                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  When to use which:                                              â”‚
â”‚  â€¢ RED: Simple, request-focused services                         â”‚
â”‚  â€¢ Golden Signals: When you also need resource visibility        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Common Pitfalls

### 1. Using Averages for Duration

```
âŒ Bad: Average response time = 150ms
   Problem: Hides bimodal distributions and tail latency

âœ… Good: P50=45ms, P95=200ms, P99=800ms
   Benefit: Shows true distribution
```

### 2. Not Separating Error Types

```
âŒ Bad: Total error count = 500
   Problem: Mixes client errors (400s) with server errors (500s)

âœ… Good: 
   - 5xx errors: 50 (server problems - you need to fix)
   - 4xx errors: 450 (client issues - monitor, don't alert)
```

### 3. Too Many Label Dimensions

```
âŒ Bad: Labels = {user_id, request_id, timestamp, ...}
   Problem: Cardinality explosion, expensive storage

âœ… Good: Labels = {endpoint, method, status_code}
   Benefit: Manageable cardinality, useful aggregations
```

### 4. Ignoring Error Rate During Low Traffic

```
âŒ Bad: Alert when errors > 100/s
   Problem: Misses issues during low-traffic periods

âœ… Good: Alert when error_rate > 1%
   Benefit: Works at any traffic level
```

---

## Tools and Examples

### Prometheus Metrics Definition

```python
from prometheus_client import Counter, Histogram

# RED Metrics
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint'],
    buckets=[.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10]
)

# Note: Errors are derived from REQUEST_COUNT where status=~"5.."
```

### Grafana Dashboard JSON (Key Panels)

```json
{
  "panels": [
    {
      "title": "Request Rate",
      "type": "timeseries",
      "targets": [{
        "expr": "sum(rate(http_requests_total[5m]))",
        "legendFormat": "Total req/s"
      }]
    },
    {
      "title": "Error Rate",
      "type": "timeseries",
      "targets": [{
        "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100",
        "legendFormat": "Error %"
      }]
    },
    {
      "title": "Duration Percentiles",
      "type": "timeseries",
      "targets": [
        {"expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))", "legendFormat": "P50"},
        {"expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))", "legendFormat": "P95"},
        {"expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))", "legendFormat": "P99"}
      ]
    }
  ]
}
```

---

## Summary

| Metric | What It Measures | Key Questions |
|--------|------------------|---------------|
| **Rate** | Request throughput | How busy is the service? |
| **Errors** | Failure count/rate | How often are requests failing? |
| **Duration** | Response time distribution | How long are requests taking? |

### Key Takeaways

1. **Simple and consistent** - Same three metrics for every service
2. **User-focused** - Metrics directly reflect user experience
3. **Use histograms** for duration, not averages
4. **Separate error types** - 5xx vs. 4xx have different meanings
5. **Combine with USE** for complete visibility (resources + requests)

---

## Related Documentation

- [Golden Signals](03-golden-signals.md) - More comprehensive methodology
- [USE Method](05-use-method.md) - Resource-focused monitoring
- [SLI/SLO/SLA](01-sli-slo-sla.md) - Setting reliability targets based on RED metrics
