# DORA Metrics

## Table of Contents

- [Overview](#overview)
- [The Four Key Metrics](#the-four-key-metrics)
  - [1. Deployment Frequency](#1-deployment-frequency)
  - [2. Lead Time for Changes](#2-lead-time-for-changes)
  - [3. Change Failure Rate](#3-change-failure-rate)
  - [4. Mean Time to Recovery (MTTR)](#4-mean-time-to-recovery-mttr)
- [Performance Levels](#performance-levels)
- [The Fifth Metric: Reliability](#the-fifth-metric-reliability)
- [Measuring DORA Metrics](#measuring-dora-metrics)
- [Implementation Strategies](#implementation-strategies)
- [Common Pitfalls](#common-pitfalls)
- [Tools and Platforms](#tools-and-platforms)
- [Improving Your DORA Metrics](#improving-your-dora-metrics)
- [DORA Metrics and Business Outcomes](#dora-metrics-and-business-outcomes)

---

## Overview

**DORA Metrics** are four key metrics identified by the DevOps Research and Assessment (DORA) team through years of research. These metrics measure software delivery performance and organizational performance, providing a data-driven approach to understanding DevOps capabilities.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DORA METRICS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚     VELOCITY (Throughput)          STABILITY (Quality)          â”‚
â”‚     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•          â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•          â”‚
â”‚                                                                  â”‚
â”‚     ğŸ“ˆ Deployment                  ğŸ“‰ Change Failure            â”‚
â”‚        Frequency                      Rate                       â”‚
â”‚        "How often do we             "How often do                â”‚
â”‚         deploy?"                     deployments fail?"          â”‚
â”‚                                                                  â”‚
â”‚     â±ï¸  Lead Time for              ğŸ”§ Mean Time to              â”‚
â”‚        Changes                        Recovery                   â”‚
â”‚        "How fast from commit        "How quickly do we          â”‚
â”‚         to production?"              recover from failures?"    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why DORA Metrics Matter

The DORA research, now part of Google Cloud, has demonstrated that:

1. **High performers excel at all four metrics** - There's no trade-off between speed and stability
2. **These metrics predict organizational performance** - Teams with better DORA metrics have better business outcomes
3. **They're universally applicable** - Work across industries, company sizes, and tech stacks
4. **They drive continuous improvement** - Provide clear targets for DevOps transformation

> "Our research has found that these metrics are predictive of both software delivery performance and organizational performance, including profitability, market share, and customer satisfaction."
> â€” DORA State of DevOps Report

---

## The Four Key Metrics

### 1. Deployment Frequency

**Definition**: How often an organization successfully releases to production.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DEPLOYMENT FREQUENCY                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  WHAT TO MEASURE                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                            â”‚
â”‚  â€¢ Successful deployments to production                     â”‚
â”‚  â€¢ Per application/service (not aggregate)                  â”‚
â”‚  â€¢ Automated AND manual deployments                         â”‚
â”‚                                                              â”‚
â”‚  WHAT NOT TO MEASURE                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                        â”‚
â”‚  âœ— Deployments to non-production environments               â”‚
â”‚  âœ— Failed deployments                                       â”‚
â”‚  âœ— Rollbacks (count separately)                             â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Why It Matters

- **Faster feedback loops**: More frequent deployments mean faster user feedback
- **Smaller batch sizes**: Reduces risk and complexity per deployment
- **Higher agility**: Ability to respond quickly to market changes
- **Better flow**: Indicates healthy CI/CD pipelines and processes

#### Calculation

```
Deployment Frequency = Number of Successful Deployments / Time Period

Examples:
- Daily deployments: 5 deploys/day
- Weekly deployments: 10 deploys/week
- Monthly: 20 deploys/month
```

#### Performance Benchmarks

| Level | Deployment Frequency |
|-------|---------------------|
| Elite | On-demand (multiple deploys per day) |
| High | Between once per day and once per week |
| Medium | Between once per week and once per month |
| Low | Between once per month and once every six months |

---

### 2. Lead Time for Changes

**Definition**: The time it takes to go from code committed to code successfully running in production.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 LEAD TIME FOR CHANGES                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Code   â”‚â”€â”€â”€â–¶â”‚  Build  â”‚â”€â”€â”€â–¶â”‚  Test   â”‚â”€â”€â”€â–¶â”‚ Deploy  â”‚  â”‚
â”‚  â”‚ Commit  â”‚    â”‚ & CI    â”‚    â”‚ & QA    â”‚    â”‚ to Prod â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                             â”‚       â”‚
â”‚       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LEAD TIME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚       â”‚
â”‚                                                              â”‚
â”‚  Includes:                                                   â”‚
â”‚  â€¢ Code review time                                         â”‚
â”‚  â€¢ Build time                                               â”‚
â”‚  â€¢ Test execution time                                      â”‚
â”‚  â€¢ Deployment time                                          â”‚
â”‚  â€¢ Any manual approval wait times                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Why It Matters

- **Time to value**: How quickly can you deliver value to customers?
- **Process efficiency**: Identifies bottlenecks in your delivery pipeline
- **Competitive advantage**: Faster lead times enable faster innovation
- **Developer experience**: Long lead times frustrate developers

#### Calculation

```
Lead Time = Timestamp(Production Deployment) - Timestamp(Code Commit)

For aggregate metrics:
- Use median or percentiles (P50, P90)
- Avoid averages (can be skewed by outliers)
```

#### What to Include

| Include | Exclude |
|---------|---------|
| Code review wait time | Time before first commit (planning) |
| CI/CD pipeline duration | Feature development time |
| Manual approval wait time | Requirements gathering |
| Deployment execution time | Design and architecture time |

#### Performance Benchmarks

| Level | Lead Time for Changes |
|-------|----------------------|
| Elite | Less than one hour |
| High | Between one day and one week |
| Medium | Between one week and one month |
| Low | Between one month and six months |

---

### 3. Change Failure Rate

**Definition**: The percentage of deployments causing a failure in production that requires remediation (rollback, hotfix, patch, etc.).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CHANGE FAILURE RATE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚                    Total Deployments                         â”‚
â”‚                    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                         â”‚
â”‚                           â”‚                                  â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚            â”‚                             â”‚                   â”‚
â”‚            â–¼                             â–¼                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚  Successful â”‚              â”‚   Failed    â”‚            â”‚
â”‚     â”‚ Deployments â”‚              â”‚ Deployments â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                        â”‚                     â”‚
â”‚                                        â–¼                     â”‚
â”‚                              Requires Remediation:           â”‚
â”‚                              â€¢ Rollback                      â”‚
â”‚                              â€¢ Hotfix                        â”‚
â”‚                              â€¢ Emergency patch               â”‚
â”‚                              â€¢ Incident declared             â”‚
â”‚                                                              â”‚
â”‚  Change Failure Rate = Failed Deployments / Total Ã— 100%    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Why It Matters

- **Quality indicator**: Measures the effectiveness of your testing and review processes
- **Risk assessment**: Higher rates indicate higher deployment risk
- **Trust metric**: Teams with low CFR can deploy more confidently
- **Process health**: Reflects the maturity of CI/CD practices

#### What Counts as a Failure?

| Counts as Failure | Does NOT Count as Failure |
|-------------------|---------------------------|
| Service degradation requiring rollback | Minor bugs fixed in next release |
| Incidents caused by deployment | Planned feature flags/toggles |
| Emergency hotfixes needed | Configuration changes |
| Customer-impacting issues | Cosmetic issues |
| SLO violations caused by change | Issues caught in canary/staged rollout |

#### Calculation

```
Change Failure Rate = (Failed Deployments / Total Deployments) Ã— 100%

Example:
- 100 deployments in a month
- 8 required rollback or hotfix
- CFR = 8/100 = 8%
```

#### Performance Benchmarks

| Level | Change Failure Rate |
|-------|---------------------|
| Elite | 0-15% |
| High | 16-30% |
| Medium | 16-30% |
| Low | 46-60% |

---

### 4. Mean Time to Recovery (MTTR)

**Definition**: How long it takes to recover from a failure in production (service outage, degradation, or incident).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MEAN TIME TO RECOVERY                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Timeline of an Incident:                                   â”‚
â”‚                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
â”‚  â”‚         â”‚              â”‚              â”‚         â”‚        â”‚
â”‚  Failure   Detection      Response       Resolution Service â”‚
â”‚  Occurs    (Alert)        Begins         Applied    Restoredâ”‚
â”‚  â”‚         â”‚              â”‚              â”‚         â”‚        â”‚
â”‚  â”‚â—„â”€MTTDâ”€â”€â–¶â”‚â—„â”€â”€â”€MTTAâ”€â”€â”€â”€â–¶â”‚â—„â”€â”€â”€â”€MTTRâ”€â”€â”€â”€â–¶â”‚         â”‚        â”‚
â”‚  â”‚                                                 â”‚        â”‚
â”‚  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MTTR (Total) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚        â”‚
â”‚                                                              â”‚
â”‚  MTTD = Mean Time to Detect                                 â”‚
â”‚  MTTA = Mean Time to Acknowledge                            â”‚
â”‚  MTTR = Mean Time to Repair/Resolve                         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Why It Matters

- **Resilience indicator**: Shows how quickly you can bounce back
- **User impact**: Directly correlates to downtime experienced by users
- **Operational maturity**: Reflects incident response capabilities
- **SLA compliance**: Critical for meeting availability commitments

#### What to Measure

| Include | Considerations |
|---------|---------------|
| Time from incident start to service restoration | Use consistent start/end definitions |
| All production incidents | Track by severity level |
| Both deployment and non-deployment failures | Separate if needed for analysis |

#### Calculation

```
MTTR = Sum of All Recovery Times / Number of Incidents

Example:
- Incident 1: 45 minutes to recover
- Incident 2: 120 minutes to recover
- Incident 3: 30 minutes to recover
- MTTR = (45 + 120 + 30) / 3 = 65 minutes
```

#### Performance Benchmarks

| Level | Time to Restore Service |
|-------|------------------------|
| Elite | Less than one hour |
| High | Less than one day |
| Medium | Between one day and one week |
| Low | More than six months |

---

## Performance Levels

The DORA research categorizes teams into four performance levels:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DORA PERFORMANCE LEVELS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ELITE                                                          â”‚
â”‚  â•â•â•â•â•                                                          â”‚
â”‚  â€¢ Deploy: On-demand (multiple per day)                         â”‚
â”‚  â€¢ Lead Time: < 1 hour                                          â”‚
â”‚  â€¢ CFR: 0-15%                                                   â”‚
â”‚  â€¢ MTTR: < 1 hour                                               â”‚
â”‚                                                                  â”‚
â”‚  HIGH                                                           â”‚
â”‚  â•â•â•â•                                                           â”‚
â”‚  â€¢ Deploy: Daily to weekly                                      â”‚
â”‚  â€¢ Lead Time: 1 day to 1 week                                   â”‚
â”‚  â€¢ CFR: 16-30%                                                  â”‚
â”‚  â€¢ MTTR: < 1 day                                                â”‚
â”‚                                                                  â”‚
â”‚  MEDIUM                                                         â”‚
â”‚  â•â•â•â•â•â•                                                         â”‚
â”‚  â€¢ Deploy: Weekly to monthly                                    â”‚
â”‚  â€¢ Lead Time: 1 week to 1 month                                 â”‚
â”‚  â€¢ CFR: 16-30%                                                  â”‚
â”‚  â€¢ MTTR: 1 day to 1 week                                        â”‚
â”‚                                                                  â”‚
â”‚  LOW                                                            â”‚
â”‚  â•â•â•                                                            â”‚
â”‚  â€¢ Deploy: Monthly to semi-annually                             â”‚
â”‚  â€¢ Lead Time: 1 to 6 months                                     â”‚
â”‚  â€¢ CFR: 46-60%                                                  â”‚
â”‚  â€¢ MTTR: > 6 months                                             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Level Comparison

| Metric | Elite | High | Medium | Low |
|--------|-------|------|--------|-----|
| **Deployment Frequency** | On-demand (multiple/day) | Daily to weekly | Weekly to monthly | Monthly to semi-annually |
| **Lead Time for Changes** | < 1 hour | 1 day - 1 week | 1 week - 1 month | 1 - 6 months |
| **Change Failure Rate** | 0-15% | 16-30% | 16-30% | 46-60% |
| **Time to Restore** | < 1 hour | < 1 day | 1 day - 1 week | > 6 months |

---

## The Fifth Metric: Reliability

In recent years, DORA has added a fifth metric focused on operational performance:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RELIABILITY                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Definition: Meeting or exceeding reliability targets        â”‚
â”‚                                                              â”‚
â”‚  Measured through:                                          â”‚
â”‚  â€¢ SLO achievement rate                                     â”‚
â”‚  â€¢ Availability percentage                                  â”‚
â”‚  â€¢ Error budget consumption                                 â”‚
â”‚                                                              â”‚
â”‚  Why Added:                                                 â”‚
â”‚  â€¢ Balances velocity with stability                         â”‚
â”‚  â€¢ Directly ties to user experience                         â”‚
â”‚  â€¢ Aligns with SRE practices                                â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  "Operational performance is a key factor in        â”‚    â”‚
â”‚  â”‚   overall organizational performance"               â”‚    â”‚
â”‚  â”‚                      â€” DORA 2021 Report             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Measuring DORA Metrics

### Data Sources

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DATA SOURCES FOR DORA METRICS                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  DEPLOYMENT FREQUENCY                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  â€¢ CI/CD pipeline logs (Jenkins, GitHub Actions, GitLab)    â”‚
â”‚  â€¢ Deployment tools (ArgoCD, Spinnaker, Octopus)           â”‚
â”‚  â€¢ Change management systems                                â”‚
â”‚                                                              â”‚
â”‚  LEAD TIME FOR CHANGES                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  â€¢ Version control systems (Git commits)                    â”‚
â”‚  â€¢ CI/CD pipeline timestamps                                â”‚
â”‚  â€¢ Deployment logs with commit SHA references               â”‚
â”‚                                                              â”‚
â”‚  CHANGE FAILURE RATE                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  â€¢ Incident management systems (PagerDuty, Opsgenie)        â”‚
â”‚  â€¢ Rollback logs from deployment tools                      â”‚
â”‚  â€¢ Post-incident reviews/RCAs                               â”‚
â”‚                                                              â”‚
â”‚  MEAN TIME TO RECOVERY                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  â€¢ Incident management systems                              â”‚
â”‚  â€¢ Monitoring/alerting platforms                            â”‚
â”‚  â€¢ Status page history                                      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Measurement Best Practices

| Practice | Description |
|----------|-------------|
| **Automate collection** | Manual tracking is error-prone and unsustainable |
| **Measure per service** | Aggregate metrics hide important variations |
| **Use consistent definitions** | Document what counts as deployment, failure, etc. |
| **Track trends over time** | Point-in-time values are less meaningful |
| **Segment by team/service** | Enable team-level improvement efforts |

### Sample Dashboard Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DORA METRICS DASHBOARD                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Deployment Frequency â”‚  â”‚ Lead Time for Changesâ”‚        â”‚
â”‚  â”‚                      â”‚  â”‚                      â”‚        â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 12/dayâ”‚  â”‚   P50: 2.3 hours    â”‚        â”‚
â”‚  â”‚   â–² 20% vs last week â”‚  â”‚   P90: 8.1 hours    â”‚        â”‚
â”‚  â”‚                      â”‚  â”‚   â–¼ 15% improvement â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Change Failure Rate  â”‚  â”‚ Mean Time to Recoveryâ”‚        â”‚
â”‚  â”‚                      â”‚  â”‚                      â”‚        â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  8%   â”‚  â”‚   Average: 47 min   â”‚        â”‚
â”‚  â”‚   â–¼ 3% vs last month â”‚  â”‚   P90: 2.1 hours    â”‚        â”‚
â”‚  â”‚                      â”‚  â”‚   â–² 10% slower      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                              â”‚
â”‚  Performance Level: HIGH â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â†’ ELITE      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Strategies

### Getting Started

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DORA METRICS IMPLEMENTATION ROADMAP             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  PHASE 1: Foundation (Weeks 1-4)                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                            â”‚
â”‚  â–¡ Define what "deployment" means for your org              â”‚
â”‚  â–¡ Define what "failure" means (requires remediation)       â”‚
â”‚  â–¡ Identify data sources for each metric                    â”‚
â”‚  â–¡ Set up basic tracking (even manual initially)            â”‚
â”‚                                                              â”‚
â”‚  PHASE 2: Automation (Weeks 5-8)                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                           â”‚
â”‚  â–¡ Integrate with CI/CD pipelines                           â”‚
â”‚  â–¡ Connect to incident management                           â”‚
â”‚  â–¡ Build automated dashboards                               â”‚
â”‚  â–¡ Establish baseline measurements                          â”‚
â”‚                                                              â”‚
â”‚  PHASE 3: Optimization (Ongoing)                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                            â”‚
â”‚  â–¡ Set improvement targets                                  â”‚
â”‚  â–¡ Identify bottlenecks and constraints                     â”‚
â”‚  â–¡ Implement improvements                                   â”‚
â”‚  â–¡ Track progress and iterate                               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Questions to Answer

| Metric | Key Questions |
|--------|---------------|
| **Deployment Frequency** | What counts as production? Include feature flags? Blue-green switches? |
| **Lead Time** | From first commit or PR merge? Include weekends/holidays? |
| **Change Failure Rate** | What severity counts? Only rollbacks or also hotfixes? |
| **MTTR** | From alert or from actual failure? To full resolution or service restoration? |

---

## Common Pitfalls

### Anti-Patterns to Avoid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     COMMON PITFALLS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  âŒ GAMING THE METRICS                                      â”‚
â”‚     â€¢ Splitting deploys artificially to increase frequency  â”‚
â”‚     â€¢ Not counting failures to improve CFR                  â”‚
â”‚     â€¢ Closing incidents prematurely to improve MTTR         â”‚
â”‚                                                              â”‚
â”‚  âŒ USING METRICS PUNITIVELY                                â”‚
â”‚     â€¢ Blaming teams for poor metrics                        â”‚
â”‚     â€¢ Creating competition between teams                    â”‚
â”‚     â€¢ Tying metrics directly to performance reviews         â”‚
â”‚                                                              â”‚
â”‚  âŒ IGNORING CONTEXT                                        â”‚
â”‚     â€¢ Comparing teams with different constraints            â”‚
â”‚     â€¢ Not considering regulatory requirements               â”‚
â”‚     â€¢ Ignoring team size and maturity differences          â”‚
â”‚                                                              â”‚
â”‚  âŒ FOCUSING ON SINGLE METRICS                              â”‚
â”‚     â€¢ Optimizing deployment frequency at cost of quality    â”‚
â”‚     â€¢ Reducing lead time by skipping testing                â”‚
â”‚     â€¢ All four metrics must improve together                â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What NOT to Do

| Don't | Do Instead |
|-------|------------|
| Compare teams across different contexts | Track team improvement over time |
| Use metrics as punishment | Use metrics to identify improvement opportunities |
| Optimize one metric at expense of others | Balance all four metrics |
| Manually track metrics long-term | Automate data collection |
| Set arbitrary targets | Base targets on current baseline |

---

## Tools and Platforms

### Specialized DORA Tools

| Tool | Description | Best For |
|------|-------------|----------|
| **Google Cloud DORA** | Official DORA quick check | Assessment and benchmarking |
| **LinearB** | Developer workflow analytics | Comprehensive metrics |
| **Sleuth** | DORA metrics automation | CI/CD integration |
| **Swarmia** | Engineering effectiveness | Team-level insights |
| **Faros AI** | Engineering intelligence | Enterprise scale |
| **Jellyfish** | Engineering management | Portfolio view |

### DIY Implementation

| Component | Tools |
|-----------|-------|
| **Data Collection** | Prometheus, OpenTelemetry, custom scripts |
| **Storage** | TimescaleDB, InfluxDB, BigQuery |
| **Visualization** | Grafana, Looker, custom dashboards |
| **CI/CD Integration** | GitHub Actions, GitLab CI, Jenkins plugins |

### GitHub Actions Example

```yaml
# .github/workflows/dora-metrics.yml
name: Track DORA Metrics

on:
  deployment:
    types: [created]
  workflow_run:
    workflows: ["Deploy to Production"]
    types: [completed]

jobs:
  track-deployment:
    runs-on: ubuntu-latest
    steps:
      - name: Record Deployment
        run: |
          curl -X POST ${{ secrets.METRICS_ENDPOINT }} \
            -H "Content-Type: application/json" \
            -d '{
              "event": "deployment",
              "timestamp": "${{ github.event.deployment.created_at }}",
              "commit_sha": "${{ github.sha }}",
              "status": "${{ github.event.deployment.status }}",
              "service": "${{ github.repository }}"
            }'
```

---

## Improving Your DORA Metrics

### Deployment Frequency Improvements

| Improvement | Impact |
|-------------|--------|
| Implement trunk-based development | Reduces merge conflicts, enables continuous deployment |
| Automate testing | Removes manual gates |
| Use feature flags | Decouple deployment from release |
| Reduce batch size | Smaller changes are easier to deploy |

### Lead Time Improvements

| Improvement | Impact |
|-------------|--------|
| Automate CI/CD pipeline | Eliminates manual steps |
| Parallelize tests | Reduces pipeline duration |
| Implement fast feedback | Catch issues earlier |
| Reduce code review wait time | Use async reviews, pair programming |

### Change Failure Rate Improvements

| Improvement | Impact |
|-------------|--------|
| Increase test coverage | Catch bugs before production |
| Implement canary deployments | Limit blast radius |
| Use progressive delivery | Gradual rollout reduces risk |
| Improve code review quality | Catch issues before merge |

### MTTR Improvements

| Improvement | Impact |
|-------------|--------|
| Improve observability | Faster detection and diagnosis |
| Implement runbooks | Standardized response procedures |
| Practice incident response | Team readiness |
| Enable fast rollbacks | Quick mitigation option |

---

## DORA Metrics and Business Outcomes

### Research Findings

The DORA research has consistently shown correlations between software delivery performance and:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             DORA METRICS â†’ BUSINESS OUTCOMES                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ORGANIZATIONAL PERFORMANCE                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                 â”‚
â”‚  â€¢ Profitability                                            â”‚
â”‚  â€¢ Market share                                             â”‚
â”‚  â€¢ Productivity                                             â”‚
â”‚                                                              â”‚
â”‚  COMMERCIAL PERFORMANCE                                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                     â”‚
â”‚  â€¢ Number of customers                                      â”‚
â”‚  â€¢ Operating efficiency                                     â”‚
â”‚  â€¢ Customer satisfaction                                    â”‚
â”‚                                                              â”‚
â”‚  NON-COMMERCIAL PERFORMANCE                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                â”‚
â”‚  â€¢ Mission achievement                                      â”‚
â”‚  â€¢ Quality of products/services                             â”‚
â”‚  â€¢ Stakeholder satisfaction                                 â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Elite performers are 2x more likely to meet or     â”‚    â”‚
â”‚  â”‚  exceed organizational performance goals            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Connecting Technical and Business Metrics

| DORA Metric | Business Impact |
|-------------|-----------------|
| **High Deployment Frequency** | Faster time-to-market, competitive advantage |
| **Low Lead Time** | Quicker response to customer needs |
| **Low Change Failure Rate** | Higher quality, better customer experience |
| **Low MTTR** | Higher availability, better SLA compliance |

---

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DORA METRICS QUICK REFERENCE                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  DEPLOYMENT FREQUENCY        LEAD TIME FOR CHANGES          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•         â”‚
â”‚  How often to production?    Commit â†’ Production time       â”‚
â”‚  Elite: Multiple/day         Elite: < 1 hour                â”‚
â”‚  High: Daily-Weekly          High: < 1 week                 â”‚
â”‚  Medium: Weekly-Monthly      Medium: < 1 month              â”‚
â”‚  Low: Monthly-Semi-annually  Low: 1-6 months                â”‚
â”‚                                                              â”‚
â”‚  CHANGE FAILURE RATE         MEAN TIME TO RECOVERY          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•          â”‚
â”‚  % deploys causing failure   Time to restore service        â”‚
â”‚  Elite: 0-15%                Elite: < 1 hour                â”‚
â”‚  High: 16-30%                High: < 1 day                  â”‚
â”‚  Medium: 16-30%              Medium: < 1 week               â”‚
â”‚  Low: 46-60%                 Low: > 6 months                â”‚
â”‚                                                              â”‚
â”‚  KEY PRINCIPLE: High performers excel at ALL four metrics   â”‚
â”‚  There is NO trade-off between speed and stability!         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Related Documentation

- [SLI/SLO/SLA](01-sli-slo-sla.md) - Service level metrics for reliability targets
- [Error Budget](02-error-budget.md) - Balancing reliability with velocity
- [MTTR/MTTF/MTBF](06-mttr-mttf-mtbf.md) - Detailed time-based reliability metrics
- [Well-Known Metrics Catalog](09-well-known-metrics-catalog.md) - Comprehensive metrics reference

---

## References

- [DORA State of DevOps Reports](https://dora.dev)
- [Accelerate: The Science of Lean Software and DevOps](https://itrevolution.com/book/accelerate/)
- [Google Cloud DORA Metrics](https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance)

---

*Last Updated: December 2025*
